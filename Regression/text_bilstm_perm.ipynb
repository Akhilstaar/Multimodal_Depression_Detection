{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lDyrdz70szBD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t9k-lAreszEy"
      },
      "outputs": [],
      "source": [
        "prefix = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "text_features = np.load(os.path.join(prefix, './Features/TextWhole/whole_samples_reg_avg.npz'))['arr_0']\n",
        "text_targets = np.load(os.path.join(prefix, './Features/TextWhole/whole_labels_reg_avg.npz'))['arr_0']\n",
        "\n",
        "audio_features = np.squeeze(np.load(os.path.join(prefix, './Features/AudioWhole/whole_samples_reg_256.npz'))['arr_0'], axis=2)\n",
        "audio_targets = np.load(os.path.join(prefix, './Features/AudioWhole/whole_labels_reg_256.npz'))['arr_0']\n",
        "\n",
        "\n",
        "audio_dep_idxs = np.where(audio_targets >= 53)[0]\n",
        "audio_non_idxs = np.where(audio_targets < 53)[0]\n",
        "\n",
        "# dep_orders = random.sample(range(len(audio_dep_idxs)), len(audio_dep_idxs))\n",
        "# non_orders = random.sample(range(len(audio_non_idxs)), len(audio_non_idxs))\n",
        "# dep_idxs = audio_dep_idxs[dep_orders]\n",
        "# non_idxs = audio_non_idxs[non_orders]\n",
        "# np.save(os.path.join(prefix, './Features/AudioWhole/dep_idxs'), dep_idxs)\n",
        "# np.save(os.path.join(prefix, './Features/AudioWhole/non_idxs'), non_idxs)\n",
        "\n",
        "dep_idxs = np.load(os.path.join(prefix, './Features/AudioWhole/dep_idxs.npy'), allow_pickle=True)\n",
        "non_idxs = np.load(os.path.join(prefix, './Features/AudioWhole/non_idxs.npy'), allow_pickle=True)\n",
        "\n",
        "config = {\n",
        "    'num_classes': 1,\n",
        "    'dropout': 0.5,\n",
        "    'rnn_layers': 2,\n",
        "    'embedding_size': 1024,\n",
        "    'batch_size': 2,\n",
        "    'epochs': 150,\n",
        "    'learning_rate': 1e-5,\n",
        "    'hidden_dims': 128,\n",
        "    'bidirectional': True,\n",
        "    'cuda': False,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yVCT4qKSszG9"
      },
      "outputs": [],
      "source": [
        "class TextBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TextBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # lstm\n",
        "        self.lstm_net = nn.LSTM(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=self.bidirectional)\n",
        "\n",
        "        # self.init_weight()\n",
        "\n",
        "        # FC\n",
        "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            nn.ReLU(),\n",
        "            # nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x : [len_seq, batch_size, embedding_dim]\n",
        "        x = x.permute(1, 0, 2)\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm_net(x)\n",
        "        # output : [batch_size, len_seq, n_hidden * 2]\n",
        "        output = output.permute(1, 0, 2)\n",
        "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "        # atten_out = self.attention_net(output, final_hidden_state)\n",
        "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "        return self.fc_out(atten_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "78wrM9f1szI-"
      },
      "outputs": [],
      "source": [
        "def save(model, filename):\n",
        "    save_filename = '{}.pt'.format(filename)\n",
        "    torch.save(model, save_filename)\n",
        "    print('Saved as %s' % save_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-fk_3xuXszLA"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    global lr, train_acc\n",
        "    model.train()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    pred = np.array([])\n",
        "    X_train = text_features[train_dep_idxs+train_non_idxs]\n",
        "    Y_train = text_targets[train_dep_idxs+train_non_idxs]\n",
        "    for i in range(0, X_train.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_train.shape[0]:\n",
        "            x, y = X_train[i:], Y_train[i:]\n",
        "        else:\n",
        "            x, y = X_train[i:(i + config['batch_size'])], Y_train[i:(\n",
        "                i + config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(y)).type(torch.FloatTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y.view_as(output))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_idx += 1\n",
        "        pred = np.hstack((pred, output.flatten().detach().numpy()))\n",
        "        total_loss += loss.item()\n",
        "    train_mae = mean_absolute_error(Y_train, pred)\n",
        "\n",
        "    print('Train Epoch: {:2d}\\t Learning rate: {:.4f}\\t Loss: {:.4f}\\t MAE: {:.4f}\\t RMSE: {:.4f}\\n '\n",
        "        .format(epoch + 1, config['learning_rate'], total_loss, train_mae, \\\n",
        "            np.sqrt(mean_squared_error(Y_train, pred))))\n",
        "    return train_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Sb9cJSUzszM2"
      },
      "outputs": [],
      "source": [
        "def evaluate(fold, model, train_mae):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    global min_mae, min_rmse, test_dep_idxs, test_non_idxs\n",
        "    pred = np.array([])\n",
        "    X_test = text_features[list(test_dep_idxs)+list(test_non_idxs)]\n",
        "    Y_test = text_targets[list(test_dep_idxs)+list(test_non_idxs)]\n",
        "    with torch.no_grad():\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(X_test).type(torch.FloatTensor), requires_grad=True).cuda(),\\\n",
        "                Variable(torch.from_numpy(Y_test)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(X_test).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(Y_test)).type(torch.FloatTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y.view_as(output))\n",
        "        total_loss += loss.item()\n",
        "        pred = output.flatten().detach().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(Y_test, pred)\n",
        "        rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "\n",
        "        print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "        print('='*89)\n",
        "\n",
        "        if mae <= min_mae and mae < 8.5 and train_mae < 13:\n",
        "            min_mae = mae\n",
        "            min_rmse = rmse\n",
        "            mode = 'bi' if config['bidirectional'] else 'norm'\n",
        "            mode ='gru'\n",
        "            save(model, '../Model/Regression/Text{}/BiLSTM_{}_{:.2f}'.format(fold+1, config['hidden_dims'], min_mae))\n",
        "            print('*' * 64) \n",
        "            print('model saved: mae: {}\\t rmse: {}'.format(min_mae, min_rmse))\n",
        "            print('*' * 64)\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfnn6Zj5szDD",
        "outputId": "426771a9-87ba-4f25-a1f7-d4bd8f64b746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4469.0280\t MAE: 50.7138\t RMSE: 51.8413\n",
            " \n",
            "MAE: 46.2554\t RMSE: 47.6109\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4461.2120\t MAE: 50.6260\t RMSE: 51.7588\n",
            " \n",
            "MAE: 46.1051\t RMSE: 47.4650\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4448.4278\t MAE: 50.4823\t RMSE: 51.6199\n",
            " \n",
            "MAE: 45.9158\t RMSE: 47.2811\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4427.7223\t MAE: 50.2497\t RMSE: 51.3938\n",
            " \n",
            "MAE: 45.6308\t RMSE: 47.0043\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4399.5599\t MAE: 49.9333\t RMSE: 51.0910\n",
            " \n",
            "MAE: 45.2067\t RMSE: 46.5928\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4354.7189\t MAE: 49.4294\t RMSE: 50.6171\n",
            " \n",
            "MAE: 44.5293\t RMSE: 45.9361\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4274.6843\t MAE: 48.5302\t RMSE: 49.7472\n",
            " \n",
            "MAE: 43.3982\t RMSE: 44.8407\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4166.8457\t MAE: 47.3185\t RMSE: 48.6049\n",
            " \n",
            "MAE: 41.7046\t RMSE: 43.2047\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 4033.5021\t MAE: 45.8202\t RMSE: 47.1579\n",
            " \n",
            "MAE: 39.4905\t RMSE: 41.0727\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 3806.4944\t MAE: 43.2696\t RMSE: 44.8033\n",
            " \n",
            "MAE: 36.6513\t RMSE: 38.3517\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 3595.6664\t MAE: 40.9007\t RMSE: 42.4533\n",
            " \n",
            "MAE: 33.5559\t RMSE: 35.4055\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 3334.9139\t MAE: 37.9709\t RMSE: 39.7161\n",
            " \n",
            "MAE: 30.4272\t RMSE: 32.4558\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 3038.4376\t MAE: 34.6378\t RMSE: 36.6084\n",
            " \n",
            "MAE: 27.3600\t RMSE: 29.5993\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 2806.1813\t MAE: 32.0301\t RMSE: 34.1872\n",
            " \n",
            "MAE: 24.5089\t RMSE: 26.9857\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 2604.2616\t MAE: 29.7594\t RMSE: 32.1054\n",
            " \n",
            "MAE: 21.8013\t RMSE: 24.5525\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 2336.2276\t MAE: 26.7497\t RMSE: 29.4864\n",
            " \n",
            "MAE: 19.2380\t RMSE: 22.3074\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 2120.1305\t MAE: 24.3198\t RMSE: 27.1844\n",
            " \n",
            "MAE: 16.8378\t RMSE: 20.2090\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 1912.9660\t MAE: 21.9931\t RMSE: 25.1491\n",
            " \n",
            "MAE: 14.8396\t RMSE: 18.4469\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 1756.9377\t MAE: 20.2351\t RMSE: 23.2676\n",
            " \n",
            "MAE: 13.1724\t RMSE: 16.9421\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 1667.5525\t MAE: 19.2344\t RMSE: 22.4199\n",
            " \n",
            "MAE: 11.7186\t RMSE: 15.6564\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1502.3661\t MAE: 17.3720\t RMSE: 20.4241\n",
            " \n",
            "MAE: 10.5691\t RMSE: 14.6191\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1571.3656\t MAE: 18.1491\t RMSE: 21.2419\n",
            " \n",
            "MAE: 9.7906\t RMSE: 13.8249\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 1314.5528\t MAE: 15.2666\t RMSE: 18.2682\n",
            " \n",
            "MAE: 9.1437\t RMSE: 13.1380\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 1210.7376\t MAE: 14.0938\t RMSE: 17.6484\n",
            " \n",
            "MAE: 8.5829\t RMSE: 12.5542\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 1216.3878\t MAE: 14.1564\t RMSE: 16.7128\n",
            " \n",
            "MAE: 8.2857\t RMSE: 12.1266\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 1194.2000\t MAE: 13.9105\t RMSE: 16.8230\n",
            " \n",
            "MAE: 8.1758\t RMSE: 11.8211\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 1189.4913\t MAE: 13.8531\t RMSE: 16.6743\n",
            " \n",
            "MAE: 8.1273\t RMSE: 11.6231\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 1082.8334\t MAE: 12.6618\t RMSE: 15.3989\n",
            " \n",
            "MAE: 8.2024\t RMSE: 11.4468\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Text1/BiLSTM_128_8.20.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.202369266086155\t rmse: 11.44678593603469\n",
            "****************************************************************\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 1075.9860\t MAE: 12.5823\t RMSE: 14.9676\n",
            " \n",
            "MAE: 8.2851\t RMSE: 11.3524\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 1061.8674\t MAE: 12.4281\t RMSE: 15.2843\n",
            " \n",
            "MAE: 8.3608\t RMSE: 11.3094\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 1046.6035\t MAE: 12.2470\t RMSE: 15.4164\n",
            " \n",
            "MAE: 8.4301\t RMSE: 11.2903\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 1012.3525\t MAE: 11.8707\t RMSE: 14.6467\n",
            " \n",
            "MAE: 8.5238\t RMSE: 11.2895\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 934.8157\t MAE: 10.9944\t RMSE: 13.8153\n",
            " \n",
            "MAE: 8.6195\t RMSE: 11.3051\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 1015.5392\t MAE: 11.9008\t RMSE: 14.3110\n",
            " \n",
            "MAE: 8.6843\t RMSE: 11.3251\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 1009.9805\t MAE: 11.8425\t RMSE: 14.6430\n",
            " \n",
            "MAE: 8.8078\t RMSE: 11.3693\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 996.6899\t MAE: 11.6907\t RMSE: 14.5191\n",
            " \n",
            "MAE: 8.9259\t RMSE: 11.4240\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 1049.4324\t MAE: 12.2873\t RMSE: 15.2301\n",
            " \n",
            "MAE: 8.9862\t RMSE: 11.4573\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 977.6606\t MAE: 11.4659\t RMSE: 14.1098\n",
            " \n",
            "MAE: 9.0660\t RMSE: 11.5066\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 1039.8699\t MAE: 12.1772\t RMSE: 14.9747\n",
            " \n",
            "MAE: 9.1295\t RMSE: 11.5431\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 978.2419\t MAE: 11.4826\t RMSE: 14.3602\n",
            " \n",
            "MAE: 9.1610\t RMSE: 11.5596\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 990.2440\t MAE: 11.6137\t RMSE: 14.4049\n",
            " \n",
            "MAE: 9.2842\t RMSE: 11.6282\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 958.1008\t MAE: 11.2515\t RMSE: 14.1049\n",
            " \n",
            "MAE: 9.3693\t RMSE: 11.6758\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 980.7256\t MAE: 11.5149\t RMSE: 14.3284\n",
            " \n",
            "MAE: 9.4409\t RMSE: 11.7180\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 1018.5500\t MAE: 11.9316\t RMSE: 14.7626\n",
            " \n",
            "MAE: 9.5088\t RMSE: 11.7600\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 994.2656\t MAE: 11.6637\t RMSE: 14.7297\n",
            " \n",
            "MAE: 9.5757\t RMSE: 11.8032\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 920.1553\t MAE: 10.8340\t RMSE: 13.4104\n",
            " \n",
            "MAE: 9.6353\t RMSE: 11.8432\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 981.1600\t MAE: 11.5077\t RMSE: 13.9346\n",
            " \n",
            "MAE: 9.6690\t RMSE: 11.8663\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 1002.0829\t MAE: 11.7502\t RMSE: 14.3437\n",
            " \n",
            "MAE: 9.7514\t RMSE: 11.9203\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 1004.8089\t MAE: 11.7782\t RMSE: 14.6369\n",
            " \n",
            "MAE: 9.7498\t RMSE: 11.9192\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 944.3105\t MAE: 11.1005\t RMSE: 13.7804\n",
            " \n",
            "MAE: 9.8282\t RMSE: 11.9727\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 921.0620\t MAE: 10.8431\t RMSE: 13.4503\n",
            " \n",
            "MAE: 9.8409\t RMSE: 11.9815\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 969.4366\t MAE: 11.3805\t RMSE: 13.9648\n",
            " \n",
            "MAE: 9.9004\t RMSE: 12.0220\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 999.6364\t MAE: 11.7223\t RMSE: 14.4743\n",
            " \n",
            "MAE: 9.9375\t RMSE: 12.0468\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 973.7072\t MAE: 11.4290\t RMSE: 14.2851\n",
            " \n",
            "MAE: 9.9013\t RMSE: 12.0226\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 935.0105\t MAE: 10.9965\t RMSE: 13.4789\n",
            " \n",
            "MAE: 9.8338\t RMSE: 11.9765\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 901.0964\t MAE: 10.6131\t RMSE: 13.1445\n",
            " \n",
            "MAE: 9.8752\t RMSE: 12.0054\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 1031.7594\t MAE: 12.0819\t RMSE: 14.9081\n",
            " \n",
            "MAE: 9.8135\t RMSE: 11.9625\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 957.2216\t MAE: 11.2475\t RMSE: 13.9431\n",
            " \n",
            "MAE: 9.8125\t RMSE: 11.9618\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 1009.3110\t MAE: 11.8341\t RMSE: 14.3448\n",
            " \n",
            "MAE: 9.7800\t RMSE: 11.9396\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 953.2650\t MAE: 11.1998\t RMSE: 14.1599\n",
            " \n",
            "MAE: 9.8058\t RMSE: 11.9571\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 990.5001\t MAE: 11.6113\t RMSE: 14.5716\n",
            " \n",
            "MAE: 9.8111\t RMSE: 11.9607\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 946.6339\t MAE: 11.1254\t RMSE: 13.8378\n",
            " \n",
            "MAE: 9.7851\t RMSE: 11.9430\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 912.5918\t MAE: 10.7468\t RMSE: 13.3261\n",
            " \n",
            "MAE: 9.8426\t RMSE: 11.9826\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 992.8562\t MAE: 11.6477\t RMSE: 14.9384\n",
            " \n",
            "MAE: 9.7596\t RMSE: 11.9257\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 1033.4777\t MAE: 12.1019\t RMSE: 14.7773\n",
            " \n",
            "MAE: 9.7858\t RMSE: 11.9435\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 1158.9782\t MAE: 13.5178\t RMSE: 16.0478\n",
            " \n",
            "MAE: 9.8171\t RMSE: 11.9650\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 980.4189\t MAE: 11.5079\t RMSE: 14.3459\n",
            " \n",
            "MAE: 9.8095\t RMSE: 11.9597\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 994.3156\t MAE: 11.6607\t RMSE: 14.8943\n",
            " \n",
            "MAE: 9.8736\t RMSE: 12.0044\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 1014.9279\t MAE: 11.8888\t RMSE: 14.8235\n",
            " \n",
            "MAE: 9.8894\t RMSE: 12.0153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 958.5122\t MAE: 11.2578\t RMSE: 14.0130\n",
            " \n",
            "MAE: 9.9678\t RMSE: 12.0679\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 984.6161\t MAE: 11.5483\t RMSE: 14.2816\n",
            " \n",
            "MAE: 9.9273\t RMSE: 12.0407\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 989.8407\t MAE: 11.6159\t RMSE: 14.1040\n",
            " \n",
            "MAE: 9.9144\t RMSE: 12.0321\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 1057.1001\t MAE: 12.3715\t RMSE: 15.0748\n",
            " \n",
            "MAE: 9.8898\t RMSE: 12.0160\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 948.9587\t MAE: 11.1446\t RMSE: 13.6149\n",
            " \n",
            "MAE: 9.9048\t RMSE: 12.0260\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 921.3114\t MAE: 10.8456\t RMSE: 13.5382\n",
            " \n",
            "MAE: 9.9152\t RMSE: 12.0330\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 1013.3580\t MAE: 11.8697\t RMSE: 14.6022\n",
            " \n",
            "MAE: 9.7941\t RMSE: 11.9497\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 926.1654\t MAE: 10.8961\t RMSE: 13.5397\n",
            " \n",
            "MAE: 9.7770\t RMSE: 11.9384\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 992.3734\t MAE: 11.6463\t RMSE: 14.2279\n",
            " \n",
            "MAE: 9.7408\t RMSE: 11.9143\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 975.9684\t MAE: 11.4491\t RMSE: 14.3489\n",
            " \n",
            "MAE: 9.7363\t RMSE: 11.9116\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 1002.6619\t MAE: 11.7607\t RMSE: 14.2880\n",
            " \n",
            "MAE: 9.6935\t RMSE: 11.8839\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 942.5767\t MAE: 11.0773\t RMSE: 13.5888\n",
            " \n",
            "MAE: 9.7572\t RMSE: 11.9258\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 954.7607\t MAE: 11.2218\t RMSE: 13.9368\n",
            " \n",
            "MAE: 9.7926\t RMSE: 11.9497\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 946.0488\t MAE: 11.1236\t RMSE: 13.7293\n",
            " \n",
            "MAE: 9.8187\t RMSE: 11.9675\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 1001.1698\t MAE: 11.7427\t RMSE: 14.4945\n",
            " \n",
            "MAE: 9.6665\t RMSE: 11.8667\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 955.7147\t MAE: 11.2343\t RMSE: 14.1564\n",
            " \n",
            "MAE: 9.7671\t RMSE: 11.9333\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 890.0686\t MAE: 10.4861\t RMSE: 13.2436\n",
            " \n",
            "MAE: 9.7237\t RMSE: 11.9052\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 1029.0866\t MAE: 12.0522\t RMSE: 14.7259\n",
            " \n",
            "MAE: 9.7510\t RMSE: 11.9235\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 935.9264\t MAE: 11.0077\t RMSE: 13.3521\n",
            " \n",
            "MAE: 9.7137\t RMSE: 11.8996\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 986.1622\t MAE: 11.5712\t RMSE: 14.3828\n",
            " \n",
            "MAE: 9.6684\t RMSE: 11.8700\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 1005.4307\t MAE: 11.7879\t RMSE: 14.4049\n",
            " \n",
            "MAE: 9.6732\t RMSE: 11.8740\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 1003.4826\t MAE: 11.7717\t RMSE: 14.6103\n",
            " \n",
            "MAE: 9.6166\t RMSE: 11.8367\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 984.9438\t MAE: 11.5633\t RMSE: 13.9529\n",
            " \n",
            "MAE: 9.6347\t RMSE: 11.8495\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 964.6509\t MAE: 11.3370\t RMSE: 13.6610\n",
            " \n",
            "MAE: 9.7108\t RMSE: 11.9007\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 925.3667\t MAE: 10.8864\t RMSE: 13.5576\n",
            " \n",
            "MAE: 9.7762\t RMSE: 11.9442\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 976.8434\t MAE: 11.4612\t RMSE: 13.7226\n",
            " \n",
            "MAE: 9.7276\t RMSE: 11.9132\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 990.0258\t MAE: 11.6201\t RMSE: 14.2353\n",
            " \n",
            "MAE: 9.7551\t RMSE: 11.9318\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 1005.3108\t MAE: 11.7897\t RMSE: 14.5076\n",
            " \n",
            "MAE: 9.7934\t RMSE: 11.9575\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 884.9857\t MAE: 10.4305\t RMSE: 13.4342\n",
            " \n",
            "MAE: 9.7200\t RMSE: 11.9101\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 947.2669\t MAE: 11.1379\t RMSE: 13.7316\n",
            " \n",
            "MAE: 9.6439\t RMSE: 11.8608\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 977.8206\t MAE: 11.4834\t RMSE: 14.1577\n",
            " \n",
            "MAE: 9.5768\t RMSE: 11.8175\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 947.1579\t MAE: 11.1335\t RMSE: 13.7869\n",
            " \n",
            "MAE: 9.5544\t RMSE: 11.8029\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 950.9707\t MAE: 11.1749\t RMSE: 14.0111\n",
            " \n",
            "MAE: 9.5127\t RMSE: 11.7761\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 892.5288\t MAE: 10.5245\t RMSE: 12.7536\n",
            " \n",
            "MAE: 9.5794\t RMSE: 11.8217\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 1005.1385\t MAE: 11.7868\t RMSE: 14.3740\n",
            " \n",
            "MAE: 9.5926\t RMSE: 11.8319\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 1005.5152\t MAE: 11.7932\t RMSE: 14.6873\n",
            " \n",
            "MAE: 9.5374\t RMSE: 11.7967\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 934.1460\t MAE: 10.9811\t RMSE: 13.6577\n",
            " \n",
            "MAE: 9.5490\t RMSE: 11.8057\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 981.2386\t MAE: 11.5166\t RMSE: 14.5552\n",
            " \n",
            "MAE: 9.5152\t RMSE: 11.7864\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 966.5626\t MAE: 11.3502\t RMSE: 14.0456\n",
            " \n",
            "MAE: 9.4355\t RMSE: 11.7426\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 989.5483\t MAE: 11.6146\t RMSE: 13.9399\n",
            " \n",
            "MAE: 9.4368\t RMSE: 11.7461\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 958.0613\t MAE: 11.2578\t RMSE: 14.0538\n",
            " \n",
            "MAE: 9.4103\t RMSE: 11.7384\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 1057.3054\t MAE: 12.3691\t RMSE: 14.8929\n",
            " \n",
            "MAE: 9.3960\t RMSE: 11.7351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 934.0655\t MAE: 10.9860\t RMSE: 13.4841\n",
            " \n",
            "MAE: 9.3521\t RMSE: 11.7147\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 932.1269\t MAE: 10.9530\t RMSE: 13.6389\n",
            " \n",
            "MAE: 9.3942\t RMSE: 11.7441\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 910.6186\t MAE: 10.7226\t RMSE: 13.5361\n",
            " \n",
            "MAE: 9.4417\t RMSE: 11.7732\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 963.1790\t MAE: 11.3073\t RMSE: 13.7746\n",
            " \n",
            "MAE: 9.3137\t RMSE: 11.7131\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 948.5546\t MAE: 11.1507\t RMSE: 13.3825\n",
            " \n",
            "MAE: 9.1673\t RMSE: 11.6615\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 963.2510\t MAE: 11.3098\t RMSE: 14.2945\n",
            " \n",
            "MAE: 9.2488\t RMSE: 11.7024\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 911.2495\t MAE: 10.7258\t RMSE: 13.8454\n",
            " \n",
            "MAE: 9.0861\t RMSE: 11.6675\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 933.5898\t MAE: 10.9843\t RMSE: 13.7670\n",
            " \n",
            "MAE: 9.2115\t RMSE: 11.7170\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 121\t Learning rate: 0.0000\t Loss: 948.6075\t MAE: 11.1534\t RMSE: 13.7408\n",
            " \n",
            "MAE: 9.1213\t RMSE: 11.7065\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 122\t Learning rate: 0.0000\t Loss: 923.2216\t MAE: 10.8646\t RMSE: 13.4484\n",
            " \n",
            "MAE: 9.0523\t RMSE: 11.7056\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 123\t Learning rate: 0.0000\t Loss: 843.1221\t MAE: 9.9551\t RMSE: 12.8398\n",
            " \n",
            "MAE: 9.1154\t RMSE: 11.7366\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 124\t Learning rate: 0.0000\t Loss: 882.1456\t MAE: 10.4093\t RMSE: 13.0155\n",
            " \n",
            "MAE: 9.0241\t RMSE: 11.7362\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 125\t Learning rate: 0.0000\t Loss: 963.1532\t MAE: 11.3079\t RMSE: 14.1820\n",
            " \n",
            "MAE: 9.0741\t RMSE: 11.7699\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 126\t Learning rate: 0.0000\t Loss: 940.0953\t MAE: 11.0525\t RMSE: 13.7846\n",
            " \n",
            "MAE: 8.9218\t RMSE: 11.7737\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 127\t Learning rate: 0.0000\t Loss: 951.6064\t MAE: 11.1850\t RMSE: 13.8588\n",
            " \n",
            "MAE: 9.0557\t RMSE: 11.7886\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 128\t Learning rate: 0.0000\t Loss: 969.3791\t MAE: 11.3872\t RMSE: 13.9027\n",
            " \n",
            "MAE: 9.1178\t RMSE: 11.7946\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 129\t Learning rate: 0.0000\t Loss: 973.1161\t MAE: 11.4273\t RMSE: 13.8194\n",
            " \n",
            "MAE: 9.1075\t RMSE: 11.7820\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 130\t Learning rate: 0.0000\t Loss: 919.9042\t MAE: 10.8306\t RMSE: 13.1159\n",
            " \n",
            "MAE: 9.1029\t RMSE: 11.8001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 131\t Learning rate: 0.0000\t Loss: 910.0288\t MAE: 10.7162\t RMSE: 13.4064\n",
            " \n",
            "MAE: 9.1369\t RMSE: 11.8194\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 132\t Learning rate: 0.0000\t Loss: 938.0068\t MAE: 11.0371\t RMSE: 13.4435\n",
            " \n",
            "MAE: 8.9622\t RMSE: 11.8276\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 133\t Learning rate: 0.0000\t Loss: 945.2560\t MAE: 11.1079\t RMSE: 13.8813\n",
            " \n",
            "MAE: 9.1384\t RMSE: 11.8368\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 134\t Learning rate: 0.0000\t Loss: 959.6758\t MAE: 11.2686\t RMSE: 14.1828\n",
            " \n",
            "MAE: 9.0680\t RMSE: 11.8553\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 135\t Learning rate: 0.0000\t Loss: 875.8220\t MAE: 10.3289\t RMSE: 12.6703\n",
            " \n",
            "MAE: 9.1306\t RMSE: 11.8714\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 136\t Learning rate: 0.0000\t Loss: 878.1888\t MAE: 10.3584\t RMSE: 12.9148\n",
            " \n",
            "MAE: 9.0063\t RMSE: 11.8818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 137\t Learning rate: 0.0000\t Loss: 895.4751\t MAE: 10.5454\t RMSE: 13.3858\n",
            " \n",
            "MAE: 9.1729\t RMSE: 11.8925\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 138\t Learning rate: 0.0000\t Loss: 850.5127\t MAE: 10.0440\t RMSE: 12.5946\n",
            " \n",
            "MAE: 9.1523\t RMSE: 11.9136\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 139\t Learning rate: 0.0000\t Loss: 974.9205\t MAE: 11.4465\t RMSE: 14.1150\n",
            " \n",
            "MAE: 8.9529\t RMSE: 11.9202\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 140\t Learning rate: 0.0000\t Loss: 885.9771\t MAE: 10.4483\t RMSE: 13.1195\n",
            " \n",
            "MAE: 9.0181\t RMSE: 11.9218\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 141\t Learning rate: 0.0000\t Loss: 988.1580\t MAE: 11.5907\t RMSE: 14.5820\n",
            " \n",
            "MAE: 9.1664\t RMSE: 11.9445\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 142\t Learning rate: 0.0000\t Loss: 908.2641\t MAE: 10.6938\t RMSE: 12.9806\n",
            " \n",
            "MAE: 9.1675\t RMSE: 11.9863\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 143\t Learning rate: 0.0000\t Loss: 818.1733\t MAE: 9.6783\t RMSE: 12.0705\n",
            " \n",
            "MAE: 9.3544\t RMSE: 12.0190\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 144\t Learning rate: 0.0000\t Loss: 844.1416\t MAE: 9.9728\t RMSE: 12.9157\n",
            " \n",
            "MAE: 9.5055\t RMSE: 12.0663\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 145\t Learning rate: 0.0000\t Loss: 941.7535\t MAE: 11.0754\t RMSE: 13.8593\n",
            " \n",
            "MAE: 9.3116\t RMSE: 12.0436\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 146\t Learning rate: 0.0000\t Loss: 877.2132\t MAE: 10.3474\t RMSE: 13.2604\n",
            " \n",
            "MAE: 9.2804\t RMSE: 12.0559\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 147\t Learning rate: 0.0000\t Loss: 901.7196\t MAE: 10.6194\t RMSE: 13.3507\n",
            " \n",
            "MAE: 9.0929\t RMSE: 12.0667\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 148\t Learning rate: 0.0000\t Loss: 860.2654\t MAE: 10.1563\t RMSE: 12.6693\n",
            " \n",
            "MAE: 9.1668\t RMSE: 12.0919\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 149\t Learning rate: 0.0000\t Loss: 873.2902\t MAE: 10.2980\t RMSE: 13.1312\n",
            " \n",
            "MAE: 9.1239\t RMSE: 12.1376\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 150\t Learning rate: 0.0000\t Loss: 840.8643\t MAE: 9.9303\t RMSE: 12.3127\n",
            " \n",
            "MAE: 9.1947\t RMSE: 12.1404\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4663.2131\t MAE: 52.8957\t RMSE: 54.4994\n",
            " \n",
            "MAE: 44.5245\t RMSE: 45.5358\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4651.8851\t MAE: 52.7684\t RMSE: 54.3818\n",
            " \n",
            "MAE: 44.3533\t RMSE: 45.3689\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4637.5114\t MAE: 52.6069\t RMSE: 54.2235\n",
            " \n",
            "MAE: 44.1179\t RMSE: 45.1395\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4612.5234\t MAE: 52.3261\t RMSE: 53.9594\n",
            " \n",
            "MAE: 43.7378\t RMSE: 44.7692\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4570.4754\t MAE: 51.8537\t RMSE: 53.4979\n",
            " \n",
            "MAE: 43.0740\t RMSE: 44.1226\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4492.8070\t MAE: 50.9810\t RMSE: 52.6785\n",
            " \n",
            "MAE: 41.9059\t RMSE: 42.9864\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4381.4947\t MAE: 49.7303\t RMSE: 51.5452\n",
            " \n",
            "MAE: 40.0689\t RMSE: 41.2028\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4186.3696\t MAE: 47.5379\t RMSE: 49.4639\n",
            " \n",
            "MAE: 37.3281\t RMSE: 38.5501\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 3968.2775\t MAE: 45.0874\t RMSE: 47.0808\n",
            " \n",
            "MAE: 34.0965\t RMSE: 35.4388\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 3702.9120\t MAE: 42.1058\t RMSE: 44.3943\n",
            " \n",
            "MAE: 30.6845\t RMSE: 32.1747\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 3438.5430\t MAE: 39.1353\t RMSE: 41.7366\n",
            " \n",
            "MAE: 27.4398\t RMSE: 29.0975\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 3103.0791\t MAE: 35.3661\t RMSE: 38.1155\n",
            " \n",
            "MAE: 24.2485\t RMSE: 26.1072\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 2797.5109\t MAE: 31.9327\t RMSE: 35.1138\n",
            " \n",
            "MAE: 21.2932\t RMSE: 23.3833\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 2595.6575\t MAE: 29.6641\t RMSE: 32.7914\n",
            " \n",
            "MAE: 18.5992\t RMSE: 20.9470\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 2427.9974\t MAE: 27.7772\t RMSE: 31.2550\n",
            " \n",
            "MAE: 16.3243\t RMSE: 18.8777\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 2204.6436\t MAE: 25.2672\t RMSE: 28.7684\n",
            " \n",
            "MAE: 14.3135\t RMSE: 17.0128\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 2030.9751\t MAE: 23.3187\t RMSE: 26.9656\n",
            " \n",
            "MAE: 12.4899\t RMSE: 15.3121\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 1897.1691\t MAE: 21.8129\t RMSE: 25.6998\n",
            " \n",
            "MAE: 11.1972\t RMSE: 13.9605\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 1733.2267\t MAE: 19.9672\t RMSE: 24.1602\n",
            " \n",
            "MAE: 10.0193\t RMSE: 12.7357\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 1652.6450\t MAE: 19.0635\t RMSE: 23.1465\n",
            " \n",
            "MAE: 9.0783\t RMSE: 11.7624\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1502.0139\t MAE: 17.3706\t RMSE: 21.6333\n",
            " \n",
            "MAE: 8.3890\t RMSE: 10.9629\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1466.3471\t MAE: 16.9703\t RMSE: 21.5671\n",
            " \n",
            "MAE: 7.9799\t RMSE: 10.4269\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 1405.4165\t MAE: 16.2875\t RMSE: 20.1531\n",
            " \n",
            "MAE: 7.7447\t RMSE: 10.0576\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 1369.7969\t MAE: 15.8869\t RMSE: 19.6015\n",
            " \n",
            "MAE: 7.6451\t RMSE: 9.8077\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 1273.4140\t MAE: 14.8000\t RMSE: 18.7778\n",
            " \n",
            "MAE: 7.6056\t RMSE: 9.6447\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 1272.3345\t MAE: 14.7906\t RMSE: 18.7226\n",
            " \n",
            "MAE: 7.6459\t RMSE: 9.5870\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 1314.6172\t MAE: 15.2653\t RMSE: 19.4599\n",
            " \n",
            "MAE: 7.6991\t RMSE: 9.5940\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 1241.0938\t MAE: 14.4419\t RMSE: 17.9254\n",
            " \n",
            "MAE: 7.8239\t RMSE: 9.6490\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 1288.6591\t MAE: 14.9730\t RMSE: 18.4562\n",
            " \n",
            "MAE: 7.9363\t RMSE: 9.7275\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 1267.4756\t MAE: 14.7292\t RMSE: 18.6126\n",
            " \n",
            "MAE: 8.0776\t RMSE: 9.8297\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 1241.6159\t MAE: 14.4370\t RMSE: 17.9201\n",
            " \n",
            "MAE: 8.2057\t RMSE: 9.9351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 1193.9876\t MAE: 13.9108\t RMSE: 16.9791\n",
            " \n",
            "MAE: 8.3569\t RMSE: 10.0459\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 1166.6466\t MAE: 13.6040\t RMSE: 17.1874\n",
            " \n",
            "MAE: 8.4827\t RMSE: 10.1436\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 1216.6809\t MAE: 14.1564\t RMSE: 17.3927\n",
            " \n",
            "MAE: 8.5830\t RMSE: 10.2276\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 1130.6452\t MAE: 13.1935\t RMSE: 16.7608\n",
            " \n",
            "MAE: 8.7209\t RMSE: 10.3515\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 1165.3997\t MAE: 13.5802\t RMSE: 16.7820\n",
            " \n",
            "MAE: 8.8301\t RMSE: 10.4566\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 1130.3976\t MAE: 13.1970\t RMSE: 16.4181\n",
            " \n",
            "MAE: 8.9812\t RMSE: 10.6116\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 1239.2350\t MAE: 14.4173\t RMSE: 17.4551\n",
            " \n",
            "MAE: 9.0621\t RMSE: 10.6990\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 1116.1365\t MAE: 13.0369\t RMSE: 16.2377\n",
            " \n",
            "MAE: 9.1973\t RMSE: 10.8518\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 1075.0414\t MAE: 12.5571\t RMSE: 16.2995\n",
            " \n",
            "MAE: 9.3232\t RMSE: 10.9995\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 1087.2447\t MAE: 12.7009\t RMSE: 16.1645\n",
            " \n",
            "MAE: 9.3554\t RMSE: 11.0332\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 1108.6246\t MAE: 12.9505\t RMSE: 16.3403\n",
            " \n",
            "MAE: 9.3823\t RMSE: 11.0611\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 1086.3709\t MAE: 12.6880\t RMSE: 16.4419\n",
            " \n",
            "MAE: 9.4980\t RMSE: 11.1837\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 1116.4027\t MAE: 13.0378\t RMSE: 16.2434\n",
            " \n",
            "MAE: 9.5952\t RMSE: 11.2895\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 1117.3262\t MAE: 13.0430\t RMSE: 16.8022\n",
            " \n",
            "MAE: 9.6472\t RMSE: 11.3471\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 1171.6584\t MAE: 13.6588\t RMSE: 16.4921\n",
            " \n",
            "MAE: 9.6683\t RMSE: 11.3706\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 1165.0875\t MAE: 13.5853\t RMSE: 17.2538\n",
            " \n",
            "MAE: 9.6441\t RMSE: 11.3432\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 1096.9574\t MAE: 12.8231\t RMSE: 15.9975\n",
            " \n",
            "MAE: 9.6847\t RMSE: 11.3888\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 1106.2677\t MAE: 12.9234\t RMSE: 15.9186\n",
            " \n",
            "MAE: 9.7451\t RMSE: 11.4573\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 1126.1944\t MAE: 13.1444\t RMSE: 15.7817\n",
            " \n",
            "MAE: 9.7536\t RMSE: 11.4668\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 1153.1358\t MAE: 13.4489\t RMSE: 16.8515\n",
            " \n",
            "MAE: 9.8464\t RMSE: 11.5744\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 1145.5622\t MAE: 13.3665\t RMSE: 16.6246\n",
            " \n",
            "MAE: 9.8590\t RMSE: 11.5890\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 1183.7356\t MAE: 13.7856\t RMSE: 16.7943\n",
            " \n",
            "MAE: 9.8297\t RMSE: 11.5544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 1176.7846\t MAE: 13.7170\t RMSE: 17.0932\n",
            " \n",
            "MAE: 9.8960\t RMSE: 11.6300\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 1128.1804\t MAE: 13.1705\t RMSE: 16.2114\n",
            " \n",
            "MAE: 9.9221\t RMSE: 11.6587\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 1125.0742\t MAE: 13.1345\t RMSE: 16.3590\n",
            " \n",
            "MAE: 9.9597\t RMSE: 11.6974\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 1061.1445\t MAE: 12.4157\t RMSE: 15.9662\n",
            " \n",
            "MAE: 9.9153\t RMSE: 11.6507\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 1086.7911\t MAE: 12.7016\t RMSE: 16.4112\n",
            " \n",
            "MAE: 9.9731\t RMSE: 11.7107\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 1102.0363\t MAE: 12.8733\t RMSE: 15.8659\n",
            " \n",
            "MAE: 10.0062\t RMSE: 11.7451\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 1127.8383\t MAE: 13.1588\t RMSE: 16.7863\n",
            " \n",
            "MAE: 10.0150\t RMSE: 11.7541\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 1126.8179\t MAE: 13.1577\t RMSE: 15.9713\n",
            " \n",
            "MAE: 10.0984\t RMSE: 11.8419\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 1135.9249\t MAE: 13.2569\t RMSE: 16.4438\n",
            " \n",
            "MAE: 10.1531\t RMSE: 11.9002\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 1037.1114\t MAE: 12.1428\t RMSE: 15.6030\n",
            " \n",
            "MAE: 10.1513\t RMSE: 11.8979\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 1132.7486\t MAE: 13.2230\t RMSE: 16.2367\n",
            " \n",
            "MAE: 10.1465\t RMSE: 11.8924\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 1153.7146\t MAE: 13.4546\t RMSE: 16.9098\n",
            " \n",
            "MAE: 10.1123\t RMSE: 11.8555\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 1136.7891\t MAE: 13.2651\t RMSE: 16.5275\n",
            " \n",
            "MAE: 10.0984\t RMSE: 11.8407\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 1088.7771\t MAE: 12.7214\t RMSE: 15.9478\n",
            " \n",
            "MAE: 10.1314\t RMSE: 11.8753\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 1208.2723\t MAE: 14.0693\t RMSE: 17.5832\n",
            " \n",
            "MAE: 10.2341\t RMSE: 11.9859\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 1083.2109\t MAE: 12.6665\t RMSE: 15.8177\n",
            " \n",
            "MAE: 10.2206\t RMSE: 11.9710\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 1233.7603\t MAE: 14.3566\t RMSE: 17.8616\n",
            " \n",
            "MAE: 10.2498\t RMSE: 12.0030\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 1152.1915\t MAE: 13.4344\t RMSE: 17.0837\n",
            " \n",
            "MAE: 10.2394\t RMSE: 11.9913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 1103.2307\t MAE: 12.8881\t RMSE: 16.0519\n",
            " \n",
            "MAE: 10.2670\t RMSE: 12.0211\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 1079.5718\t MAE: 12.6207\t RMSE: 15.9109\n",
            " \n",
            "MAE: 10.1656\t RMSE: 11.9107\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 1196.9838\t MAE: 13.9391\t RMSE: 17.4688\n",
            " \n",
            "MAE: 10.1944\t RMSE: 11.9418\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 1085.1045\t MAE: 12.6787\t RMSE: 16.0654\n",
            " \n",
            "MAE: 10.2500\t RMSE: 12.0023\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 1180.3629\t MAE: 13.7563\t RMSE: 16.9529\n",
            " \n",
            "MAE: 10.2887\t RMSE: 12.0447\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 1115.7059\t MAE: 13.0339\t RMSE: 16.1474\n",
            " \n",
            "MAE: 10.2806\t RMSE: 12.0359\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 1073.4825\t MAE: 12.5489\t RMSE: 15.5946\n",
            " \n",
            "MAE: 10.2754\t RMSE: 12.0300\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 1129.1659\t MAE: 13.1823\t RMSE: 16.3973\n",
            " \n",
            "MAE: 10.3039\t RMSE: 12.0613\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 1096.8310\t MAE: 12.8218\t RMSE: 15.8994\n",
            " \n",
            "MAE: 10.2890\t RMSE: 12.0448\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 1120.4830\t MAE: 13.0793\t RMSE: 15.9977\n",
            " \n",
            "MAE: 10.2461\t RMSE: 11.9981\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 1126.3196\t MAE: 13.1432\t RMSE: 16.1844\n",
            " \n",
            "MAE: 10.2202\t RMSE: 11.9700\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 1128.2253\t MAE: 13.1605\t RMSE: 16.3665\n",
            " \n",
            "MAE: 10.1760\t RMSE: 11.9220\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 1137.7949\t MAE: 13.2744\t RMSE: 16.8030\n",
            " \n",
            "MAE: 10.0480\t RMSE: 11.7851\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 1146.6120\t MAE: 13.3804\t RMSE: 16.3590\n",
            " \n",
            "MAE: 10.0816\t RMSE: 11.8206\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 1060.2638\t MAE: 12.4051\t RMSE: 15.1770\n",
            " \n",
            "MAE: 10.1462\t RMSE: 11.8890\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 1062.5203\t MAE: 12.4310\t RMSE: 15.6649\n",
            " \n",
            "MAE: 10.0834\t RMSE: 11.8216\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 1119.7491\t MAE: 13.0729\t RMSE: 16.2184\n",
            " \n",
            "MAE: 10.1370\t RMSE: 11.8786\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 1072.7097\t MAE: 12.5499\t RMSE: 15.8912\n",
            " \n",
            "MAE: 10.1302\t RMSE: 11.8702\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 1166.2411\t MAE: 13.5965\t RMSE: 16.6175\n",
            " \n",
            "MAE: 10.1640\t RMSE: 11.9065\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 1095.4193\t MAE: 12.7994\t RMSE: 16.5171\n",
            " \n",
            "MAE: 10.1333\t RMSE: 11.8727\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 1089.9558\t MAE: 12.7361\t RMSE: 16.1292\n",
            " \n",
            "MAE: 10.2664\t RMSE: 12.0171\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 1096.7851\t MAE: 12.8143\t RMSE: 15.5861\n",
            " \n",
            "MAE: 10.1967\t RMSE: 11.9406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 1135.6321\t MAE: 13.2527\t RMSE: 16.5003\n",
            " \n",
            "MAE: 10.2057\t RMSE: 11.9495\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 1098.6370\t MAE: 12.8353\t RMSE: 15.9658\n",
            " \n",
            "MAE: 10.2296\t RMSE: 11.9752\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 1169.5828\t MAE: 13.6342\t RMSE: 17.0327\n",
            " \n",
            "MAE: 10.2130\t RMSE: 11.9566\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 1073.7381\t MAE: 12.5548\t RMSE: 15.8694\n",
            " \n",
            "MAE: 10.1923\t RMSE: 11.9330\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 1151.8224\t MAE: 13.4236\t RMSE: 16.8905\n",
            " \n",
            "MAE: 10.1247\t RMSE: 11.8595\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 1128.4541\t MAE: 13.1722\t RMSE: 16.7518\n",
            " \n",
            "MAE: 10.2348\t RMSE: 11.9781\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 1125.1687\t MAE: 13.1293\t RMSE: 16.2161\n",
            " \n",
            "MAE: 10.1670\t RMSE: 11.9037\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 1089.4025\t MAE: 12.7322\t RMSE: 16.5135\n",
            " \n",
            "MAE: 10.1311\t RMSE: 11.8646\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 1097.9340\t MAE: 12.8354\t RMSE: 15.7729\n",
            " \n",
            "MAE: 10.2100\t RMSE: 11.9496\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 1108.1924\t MAE: 12.9345\t RMSE: 16.6198\n",
            " \n",
            "MAE: 10.2706\t RMSE: 12.0160\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 1127.8446\t MAE: 13.1655\t RMSE: 16.2874\n",
            " \n",
            "MAE: 10.2515\t RMSE: 11.9941\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 1116.3335\t MAE: 13.0356\t RMSE: 16.0919\n",
            " \n",
            "MAE: 10.2061\t RMSE: 11.9442\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 1074.1647\t MAE: 12.5512\t RMSE: 15.5235\n",
            " \n",
            "MAE: 10.2354\t RMSE: 11.9753\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 1182.3106\t MAE: 13.7838\t RMSE: 16.9122\n",
            " \n",
            "MAE: 10.2015\t RMSE: 11.9372\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 1019.1959\t MAE: 11.9408\t RMSE: 15.3546\n",
            " \n",
            "MAE: 10.2012\t RMSE: 11.9358\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 1127.7091\t MAE: 13.1677\t RMSE: 16.5727\n",
            " \n",
            "MAE: 10.2363\t RMSE: 11.9717\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 1107.6058\t MAE: 12.9396\t RMSE: 15.9211\n",
            " \n",
            "MAE: 10.1968\t RMSE: 11.9283\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 1116.5408\t MAE: 13.0387\t RMSE: 16.3962\n",
            " \n",
            "MAE: 10.1794\t RMSE: 11.9081\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 1070.7495\t MAE: 12.5152\t RMSE: 16.1088\n",
            " \n",
            "MAE: 10.1959\t RMSE: 11.9254\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 1103.3370\t MAE: 12.8917\t RMSE: 15.9339\n",
            " \n",
            "MAE: 10.1933\t RMSE: 11.9209\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 1088.5527\t MAE: 12.7176\t RMSE: 16.2794\n",
            " \n",
            "MAE: 10.2337\t RMSE: 11.9640\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 1160.3647\t MAE: 13.5353\t RMSE: 16.7055\n",
            " \n",
            "MAE: 10.1544\t RMSE: 11.8786\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 1062.9261\t MAE: 12.4416\t RMSE: 15.3486\n",
            " \n",
            "MAE: 10.2386\t RMSE: 11.9689\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 1176.3495\t MAE: 13.7122\t RMSE: 16.9744\n",
            " \n",
            "MAE: 10.1916\t RMSE: 11.9164\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 1069.8005\t MAE: 12.5089\t RMSE: 15.7934\n",
            " \n",
            "MAE: 10.1438\t RMSE: 11.8627\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 1072.1731\t MAE: 12.5338\t RMSE: 16.1708\n",
            " \n",
            "MAE: 10.1283\t RMSE: 11.8433\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 121\t Learning rate: 0.0000\t Loss: 1029.8529\t MAE: 12.0583\t RMSE: 15.0553\n",
            " \n",
            "MAE: 10.1763\t RMSE: 11.8928\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 122\t Learning rate: 0.0000\t Loss: 1087.6075\t MAE: 12.7121\t RMSE: 15.9916\n",
            " \n",
            "MAE: 10.2733\t RMSE: 11.9955\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 123\t Learning rate: 0.0000\t Loss: 1096.7507\t MAE: 12.8142\t RMSE: 15.6321\n",
            " \n",
            "MAE: 10.2274\t RMSE: 11.9430\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 124\t Learning rate: 0.0000\t Loss: 1136.6716\t MAE: 13.2658\t RMSE: 17.1933\n",
            " \n",
            "MAE: 10.0837\t RMSE: 11.7896\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 125\t Learning rate: 0.0000\t Loss: 1176.1123\t MAE: 13.7082\t RMSE: 16.7096\n",
            " \n",
            "MAE: 9.9684\t RMSE: 11.6648\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 126\t Learning rate: 0.0000\t Loss: 1079.8077\t MAE: 12.6301\t RMSE: 15.8423\n",
            " \n",
            "MAE: 9.8988\t RMSE: 11.5875\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 127\t Learning rate: 0.0000\t Loss: 1074.9030\t MAE: 12.5739\t RMSE: 15.5053\n",
            " \n",
            "MAE: 9.8169\t RMSE: 11.4966\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 128\t Learning rate: 0.0000\t Loss: 1023.2040\t MAE: 11.9908\t RMSE: 15.1089\n",
            " \n",
            "MAE: 9.8327\t RMSE: 11.5135\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 129\t Learning rate: 0.0000\t Loss: 1187.1403\t MAE: 13.8345\t RMSE: 16.5349\n",
            " \n",
            "MAE: 9.7756\t RMSE: 11.4494\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 130\t Learning rate: 0.0000\t Loss: 1084.5032\t MAE: 12.6810\t RMSE: 15.6562\n",
            " \n",
            "MAE: 9.8060\t RMSE: 11.4800\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 131\t Learning rate: 0.0000\t Loss: 1073.6462\t MAE: 12.5551\t RMSE: 15.6861\n",
            " \n",
            "MAE: 9.6539\t RMSE: 11.3122\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 132\t Learning rate: 0.0000\t Loss: 1121.9827\t MAE: 13.0995\t RMSE: 16.6062\n",
            " \n",
            "MAE: 9.6123\t RMSE: 11.2692\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 133\t Learning rate: 0.0000\t Loss: 1091.4287\t MAE: 12.7607\t RMSE: 15.4879\n",
            " \n",
            "MAE: 9.5629\t RMSE: 11.2168\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 134\t Learning rate: 0.0000\t Loss: 1054.8600\t MAE: 12.3445\t RMSE: 15.2048\n",
            " \n",
            "MAE: 9.5260\t RMSE: 11.1799\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 135\t Learning rate: 0.0000\t Loss: 1087.0948\t MAE: 12.7092\t RMSE: 16.3993\n",
            " \n",
            "MAE: 9.5833\t RMSE: 11.2396\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 136\t Learning rate: 0.0000\t Loss: 1096.7277\t MAE: 12.8171\t RMSE: 15.7601\n",
            " \n",
            "MAE: 9.4575\t RMSE: 11.1194\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 137\t Learning rate: 0.0000\t Loss: 1085.0685\t MAE: 12.6866\t RMSE: 15.6867\n",
            " \n",
            "MAE: 9.3356\t RMSE: 11.0005\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 138\t Learning rate: 0.0000\t Loss: 1095.9144\t MAE: 12.8050\t RMSE: 15.9724\n",
            " \n",
            "MAE: 9.3854\t RMSE: 11.0557\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 139\t Learning rate: 0.0000\t Loss: 1143.1057\t MAE: 13.3410\t RMSE: 16.6186\n",
            " \n",
            "MAE: 9.5298\t RMSE: 11.1991\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 140\t Learning rate: 0.0000\t Loss: 988.4464\t MAE: 11.5936\t RMSE: 15.0514\n",
            " \n",
            "MAE: 9.5275\t RMSE: 11.2011\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 141\t Learning rate: 0.0000\t Loss: 1060.4827\t MAE: 12.4096\t RMSE: 15.4224\n",
            " \n",
            "MAE: 9.4169\t RMSE: 11.1018\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 142\t Learning rate: 0.0000\t Loss: 974.2112\t MAE: 11.4418\t RMSE: 14.5666\n",
            " \n",
            "MAE: 9.6638\t RMSE: 11.3446\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 143\t Learning rate: 0.0000\t Loss: 1015.8656\t MAE: 11.9066\t RMSE: 15.2388\n",
            " \n",
            "MAE: 9.7870\t RMSE: 11.4717\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 144\t Learning rate: 0.0000\t Loss: 1095.9589\t MAE: 12.8092\t RMSE: 15.9116\n",
            " \n",
            "MAE: 9.6936\t RMSE: 11.3814\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 145\t Learning rate: 0.0000\t Loss: 1019.0491\t MAE: 11.9407\t RMSE: 15.4797\n",
            " \n",
            "MAE: 9.9107\t RMSE: 11.6006\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 146\t Learning rate: 0.0000\t Loss: 1025.6627\t MAE: 12.0105\t RMSE: 15.3153\n",
            " \n",
            "MAE: 9.8969\t RMSE: 11.5911\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 147\t Learning rate: 0.0000\t Loss: 1082.9702\t MAE: 12.6577\t RMSE: 15.8105\n",
            " \n",
            "MAE: 9.6681\t RMSE: 11.3742\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 148\t Learning rate: 0.0000\t Loss: 1146.0178\t MAE: 13.3716\t RMSE: 16.7024\n",
            " \n",
            "MAE: 9.5906\t RMSE: 11.3079\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 149\t Learning rate: 0.0000\t Loss: 967.3170\t MAE: 11.3596\t RMSE: 14.7535\n",
            " \n",
            "MAE: 9.6183\t RMSE: 11.3396\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 150\t Learning rate: 0.0000\t Loss: 1123.7859\t MAE: 13.1159\t RMSE: 16.4163\n",
            " \n",
            "MAE: 9.5779\t RMSE: 11.3119\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4612.8569\t MAE: 52.3299\t RMSE: 53.8636\n",
            " \n",
            "MAE: 45.9925\t RMSE: 47.1161\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4609.0571\t MAE: 52.2872\t RMSE: 53.8259\n",
            " \n",
            "MAE: 45.8875\t RMSE: 47.0134\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4599.3807\t MAE: 52.1784\t RMSE: 53.7228\n",
            " \n",
            "MAE: 45.7299\t RMSE: 46.8594\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4584.6183\t MAE: 52.0126\t RMSE: 53.5657\n",
            " \n",
            "MAE: 45.5029\t RMSE: 46.6377\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4564.0464\t MAE: 51.7814\t RMSE: 53.3435\n",
            " \n",
            "MAE: 45.1687\t RMSE: 46.3115\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4529.3955\t MAE: 51.3921\t RMSE: 52.9914\n",
            " \n",
            "MAE: 44.6222\t RMSE: 45.7783\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4469.5620\t MAE: 50.7198\t RMSE: 52.3342\n",
            " \n",
            "MAE: 43.6987\t RMSE: 44.8781\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4374.5280\t MAE: 49.6520\t RMSE: 51.3523\n",
            " \n",
            "MAE: 42.2053\t RMSE: 43.4248\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 4239.1946\t MAE: 48.1314\t RMSE: 49.9152\n",
            " \n",
            "MAE: 40.0475\t RMSE: 41.3308\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 4057.8292\t MAE: 46.0936\t RMSE: 48.0033\n",
            " \n",
            "MAE: 37.2215\t RMSE: 38.5991\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 3794.9234\t MAE: 43.1396\t RMSE: 45.2622\n",
            " \n",
            "MAE: 34.0019\t RMSE: 35.5047\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 3520.3995\t MAE: 40.0551\t RMSE: 42.2000\n",
            " \n",
            "MAE: 30.6586\t RMSE: 32.3172\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 3230.0899\t MAE: 36.7931\t RMSE: 39.4030\n",
            " \n",
            "MAE: 27.3798\t RMSE: 29.2247\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 2995.7697\t MAE: 34.1603\t RMSE: 36.9077\n",
            " \n",
            "MAE: 24.3255\t RMSE: 26.3844\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 2741.4685\t MAE: 31.3030\t RMSE: 34.3632\n",
            " \n",
            "MAE: 21.4806\t RMSE: 23.7868\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 2450.6967\t MAE: 28.0351\t RMSE: 31.7605\n",
            " \n",
            "MAE: 18.7870\t RMSE: 21.3278\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 2275.5272\t MAE: 26.0644\t RMSE: 29.8041\n",
            " \n",
            "MAE: 16.4381\t RMSE: 19.1536\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 2044.0233\t MAE: 23.4651\t RMSE: 27.1717\n",
            " \n",
            "MAE: 14.3525\t RMSE: 17.1873\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 1947.4374\t MAE: 22.3780\t RMSE: 26.3662\n",
            " \n",
            "MAE: 12.8177\t RMSE: 15.6227\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 1764.3019\t MAE: 20.3180\t RMSE: 24.5771\n",
            " \n",
            "MAE: 11.5547\t RMSE: 14.3126\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1611.2059\t MAE: 18.5932\t RMSE: 22.6739\n",
            " \n",
            "MAE: 10.5420\t RMSE: 13.1799\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1532.1706\t MAE: 17.7123\t RMSE: 21.6019\n",
            " \n",
            "MAE: 9.7506\t RMSE: 12.2449\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 1470.7439\t MAE: 17.0191\t RMSE: 21.2883\n",
            " \n",
            "MAE: 9.1289\t RMSE: 11.5253\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 1413.0978\t MAE: 16.3733\t RMSE: 19.6666\n",
            " \n",
            "MAE: 8.7214\t RMSE: 11.0384\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 1295.0810\t MAE: 15.0447\t RMSE: 19.1931\n",
            " \n",
            "MAE: 8.4078\t RMSE: 10.6833\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 1339.1352\t MAE: 15.5431\t RMSE: 19.5617\n",
            " \n",
            "MAE: 8.2114\t RMSE: 10.4823\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 1224.4259\t MAE: 14.2487\t RMSE: 17.8445\n",
            " \n",
            "MAE: 8.0796\t RMSE: 10.3254\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 1288.1909\t MAE: 14.9731\t RMSE: 18.5758\n",
            " \n",
            "MAE: 7.9860\t RMSE: 10.2510\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 1206.0866\t MAE: 14.0444\t RMSE: 17.2918\n",
            " \n",
            "MAE: 7.9309\t RMSE: 10.2209\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 1063.1253\t MAE: 12.4397\t RMSE: 15.6567\n",
            " \n",
            "MAE: 7.9071\t RMSE: 10.2311\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Text3/BiLSTM_128_7.91.pt\n",
            "****************************************************************\n",
            "model saved: mae: 7.907053700199834\t rmse: 10.231105537766505\n",
            "****************************************************************\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 1143.7134\t MAE: 13.3370\t RMSE: 16.8539\n",
            " \n",
            "MAE: 7.9072\t RMSE: 10.2762\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 1177.1630\t MAE: 13.7205\t RMSE: 16.7985\n",
            " \n",
            "MAE: 7.9123\t RMSE: 10.3196\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 1171.9334\t MAE: 13.6614\t RMSE: 17.1366\n",
            " \n",
            "MAE: 7.9312\t RMSE: 10.3832\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 1165.8179\t MAE: 13.5922\t RMSE: 16.7777\n",
            " \n",
            "MAE: 7.9681\t RMSE: 10.4820\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 1157.4764\t MAE: 13.4975\t RMSE: 16.9641\n",
            " \n",
            "MAE: 8.0120\t RMSE: 10.5904\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 1183.3643\t MAE: 13.7901\t RMSE: 16.9382\n",
            " \n",
            "MAE: 8.0765\t RMSE: 10.6869\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 1111.1730\t MAE: 12.9734\t RMSE: 16.3927\n",
            " \n",
            "MAE: 8.1204\t RMSE: 10.7585\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 1069.0840\t MAE: 12.5057\t RMSE: 15.9457\n",
            " \n",
            "MAE: 8.1797\t RMSE: 10.8628\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 1052.8266\t MAE: 12.3239\t RMSE: 15.4462\n",
            " \n",
            "MAE: 8.2189\t RMSE: 10.9335\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 1096.7504\t MAE: 12.8132\t RMSE: 15.7750\n",
            " \n",
            "MAE: 8.2698\t RMSE: 11.0012\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 1170.1991\t MAE: 13.6383\t RMSE: 16.9477\n",
            " \n",
            "MAE: 8.3119\t RMSE: 11.0511\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 1132.2729\t MAE: 13.2155\t RMSE: 16.4874\n",
            " \n",
            "MAE: 8.3602\t RMSE: 11.1071\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 1153.1676\t MAE: 13.4465\t RMSE: 16.5762\n",
            " \n",
            "MAE: 8.4136\t RMSE: 11.1708\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 1140.0116\t MAE: 13.3007\t RMSE: 16.4234\n",
            " \n",
            "MAE: 8.4379\t RMSE: 11.2004\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 1130.8282\t MAE: 13.2001\t RMSE: 16.6280\n",
            " \n",
            "MAE: 8.4785\t RMSE: 11.2508\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 1074.3015\t MAE: 12.5677\t RMSE: 15.6084\n",
            " \n",
            "MAE: 8.5445\t RMSE: 11.3351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 1131.1096\t MAE: 13.1997\t RMSE: 16.4560\n",
            " \n",
            "MAE: 8.5864\t RMSE: 11.3901\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 1196.8915\t MAE: 13.9420\t RMSE: 17.0852\n",
            " \n",
            "MAE: 8.6412\t RMSE: 11.4614\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 1083.3508\t MAE: 12.6678\t RMSE: 15.6312\n",
            " \n",
            "MAE: 8.6866\t RMSE: 11.5102\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 1192.4115\t MAE: 13.8908\t RMSE: 16.8382\n",
            " \n",
            "MAE: 8.6887\t RMSE: 11.5121\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 1052.9727\t MAE: 12.3211\t RMSE: 15.2116\n",
            " \n",
            "MAE: 8.7157\t RMSE: 11.5380\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 1054.7554\t MAE: 12.3445\t RMSE: 15.2739\n",
            " \n",
            "MAE: 8.6075\t RMSE: 11.4179\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 1120.8587\t MAE: 13.0875\t RMSE: 16.2810\n",
            " \n",
            "MAE: 8.6265\t RMSE: 11.4431\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 1102.9350\t MAE: 12.8865\t RMSE: 16.1113\n",
            " \n",
            "MAE: 8.6461\t RMSE: 11.4671\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 1110.9410\t MAE: 12.9788\t RMSE: 16.2930\n",
            " \n",
            "MAE: 8.6390\t RMSE: 11.4584\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 1123.0503\t MAE: 13.1069\t RMSE: 16.2945\n",
            " \n",
            "MAE: 8.6488\t RMSE: 11.4703\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 1116.7775\t MAE: 13.0442\t RMSE: 16.0102\n",
            " \n",
            "MAE: 8.7411\t RMSE: 11.5609\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 1072.6746\t MAE: 12.5471\t RMSE: 15.5315\n",
            " \n",
            "MAE: 8.7496\t RMSE: 11.5686\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 1137.3269\t MAE: 13.2697\t RMSE: 16.4471\n",
            " \n",
            "MAE: 8.7225\t RMSE: 11.5443\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 1121.5416\t MAE: 13.0958\t RMSE: 15.8412\n",
            " \n",
            "MAE: 8.7762\t RMSE: 11.5928\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 1107.6296\t MAE: 12.9400\t RMSE: 15.5648\n",
            " \n",
            "MAE: 8.7888\t RMSE: 11.6043\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 1059.4071\t MAE: 12.3960\t RMSE: 15.3786\n",
            " \n",
            "MAE: 8.7225\t RMSE: 11.5442\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 1097.7523\t MAE: 12.8239\t RMSE: 15.8370\n",
            " \n",
            "MAE: 8.7827\t RMSE: 11.5988\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 1123.6758\t MAE: 13.1141\t RMSE: 16.0830\n",
            " \n",
            "MAE: 8.7912\t RMSE: 11.6065\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 1132.4763\t MAE: 13.2162\t RMSE: 16.4114\n",
            " \n",
            "MAE: 8.7756\t RMSE: 11.5923\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 1194.6110\t MAE: 13.9156\t RMSE: 17.2364\n",
            " \n",
            "MAE: 8.8336\t RMSE: 11.6456\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 1078.0476\t MAE: 12.6002\t RMSE: 15.7491\n",
            " \n",
            "MAE: 8.7891\t RMSE: 11.6047\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 1107.9265\t MAE: 12.9376\t RMSE: 16.1396\n",
            " \n",
            "MAE: 8.6942\t RMSE: 11.5172\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 1104.0025\t MAE: 12.8961\t RMSE: 16.4434\n",
            " \n",
            "MAE: 8.7663\t RMSE: 11.5839\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 1147.3864\t MAE: 13.3839\t RMSE: 16.4646\n",
            " \n",
            "MAE: 8.8363\t RMSE: 11.6481\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 1110.2741\t MAE: 12.9664\t RMSE: 16.1623\n",
            " \n",
            "MAE: 8.8510\t RMSE: 11.6618\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 1002.8615\t MAE: 11.7601\t RMSE: 15.1505\n",
            " \n",
            "MAE: 8.7638\t RMSE: 11.5818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 1127.7848\t MAE: 13.1614\t RMSE: 16.0825\n",
            " \n",
            "MAE: 8.7200\t RMSE: 11.5419\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 1181.5583\t MAE: 13.7663\t RMSE: 17.0931\n",
            " \n",
            "MAE: 8.6494\t RMSE: 11.4705\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 1147.1941\t MAE: 13.3811\t RMSE: 16.6824\n",
            " \n",
            "MAE: 8.6359\t RMSE: 11.4541\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 1114.8022\t MAE: 13.0181\t RMSE: 16.3375\n",
            " \n",
            "MAE: 8.6202\t RMSE: 11.4342\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 1089.4939\t MAE: 12.7373\t RMSE: 15.8750\n",
            " \n",
            "MAE: 8.5944\t RMSE: 11.3995\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 1013.7788\t MAE: 11.8855\t RMSE: 15.4457\n",
            " \n",
            "MAE: 8.6261\t RMSE: 11.4419\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 959.2439\t MAE: 11.2723\t RMSE: 14.2512\n",
            " \n",
            "MAE: 8.5793\t RMSE: 11.3793\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 1190.7876\t MAE: 13.8739\t RMSE: 16.8520\n",
            " \n",
            "MAE: 8.5576\t RMSE: 11.3507\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 1164.8609\t MAE: 13.5862\t RMSE: 16.7377\n",
            " \n",
            "MAE: 8.5960\t RMSE: 11.4012\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 1088.2556\t MAE: 12.7094\t RMSE: 16.1190\n",
            " \n",
            "MAE: 8.6197\t RMSE: 11.4330\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 1033.0879\t MAE: 12.0953\t RMSE: 15.4182\n",
            " \n",
            "MAE: 8.6366\t RMSE: 11.4543\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 1085.3624\t MAE: 12.6811\t RMSE: 15.6460\n",
            " \n",
            "MAE: 8.6773\t RMSE: 11.4995\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 983.7650\t MAE: 11.5369\t RMSE: 14.7658\n",
            " \n",
            "MAE: 8.6455\t RMSE: 11.4648\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 1214.9707\t MAE: 14.1497\t RMSE: 17.3713\n",
            " \n",
            "MAE: 8.6327\t RMSE: 11.4494\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 1120.8342\t MAE: 13.0778\t RMSE: 16.2666\n",
            " \n",
            "MAE: 8.5973\t RMSE: 11.4025\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 1085.7651\t MAE: 12.6931\t RMSE: 15.4231\n",
            " \n",
            "MAE: 8.6373\t RMSE: 11.4548\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 1124.1867\t MAE: 13.1247\t RMSE: 16.3772\n",
            " \n",
            "MAE: 8.6438\t RMSE: 11.4622\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 1146.2514\t MAE: 13.3731\t RMSE: 16.3816\n",
            " \n",
            "MAE: 8.6037\t RMSE: 11.4108\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 1109.2941\t MAE: 12.9609\t RMSE: 15.7157\n",
            " \n",
            "MAE: 8.6286\t RMSE: 11.4438\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 1063.6886\t MAE: 12.4386\t RMSE: 15.4815\n",
            " \n",
            "MAE: 8.5986\t RMSE: 11.4035\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 1066.0938\t MAE: 12.4708\t RMSE: 15.4338\n",
            " \n",
            "MAE: 8.6225\t RMSE: 11.4354\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 1107.9594\t MAE: 12.9419\t RMSE: 16.1862\n",
            " \n",
            "MAE: 8.6256\t RMSE: 11.4395\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 1064.9270\t MAE: 12.4645\t RMSE: 15.3481\n",
            " \n",
            "MAE: 8.6478\t RMSE: 11.4657\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 1040.4241\t MAE: 12.1795\t RMSE: 15.4967\n",
            " \n",
            "MAE: 8.5976\t RMSE: 11.4017\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 1049.4894\t MAE: 12.2842\t RMSE: 15.2339\n",
            " \n",
            "MAE: 8.6201\t RMSE: 11.4317\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 1083.7737\t MAE: 12.6705\t RMSE: 15.5705\n",
            " \n",
            "MAE: 8.6236\t RMSE: 11.4364\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 1094.8995\t MAE: 12.7952\t RMSE: 16.1990\n",
            " \n",
            "MAE: 8.5870\t RMSE: 11.3872\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 1114.6496\t MAE: 13.0188\t RMSE: 16.3691\n",
            " \n",
            "MAE: 8.6735\t RMSE: 11.4934\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 1084.6505\t MAE: 12.6781\t RMSE: 16.5581\n",
            " \n",
            "MAE: 8.6495\t RMSE: 11.4666\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 1140.8360\t MAE: 13.3142\t RMSE: 16.4245\n",
            " \n",
            "MAE: 8.6933\t RMSE: 11.5136\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 1121.0403\t MAE: 13.0896\t RMSE: 16.1459\n",
            " \n",
            "MAE: 8.7731\t RMSE: 11.5924\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 1093.0380\t MAE: 12.7776\t RMSE: 15.6737\n",
            " \n",
            "MAE: 8.7203\t RMSE: 11.5410\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 1019.6517\t MAE: 11.9444\t RMSE: 14.8795\n",
            " \n",
            "MAE: 8.6754\t RMSE: 11.4945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 1127.0838\t MAE: 13.1509\t RMSE: 16.2305\n",
            " \n",
            "MAE: 8.7673\t RMSE: 11.5866\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 1075.0778\t MAE: 12.5661\t RMSE: 15.8726\n",
            " \n",
            "MAE: 8.8761\t RMSE: 11.6889\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 1093.2333\t MAE: 12.7719\t RMSE: 15.5820\n",
            " \n",
            "MAE: 8.8594\t RMSE: 11.6736\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 1052.4798\t MAE: 12.3157\t RMSE: 15.1586\n",
            " \n",
            "MAE: 8.8526\t RMSE: 11.6677\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 1070.8791\t MAE: 12.5304\t RMSE: 15.4761\n",
            " \n",
            "MAE: 8.8380\t RMSE: 11.6545\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 1163.8857\t MAE: 13.5740\t RMSE: 16.4723\n",
            " \n",
            "MAE: 8.7848\t RMSE: 11.6036\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 1221.3062\t MAE: 14.2123\t RMSE: 17.7723\n",
            " \n",
            "MAE: 8.6992\t RMSE: 11.5174\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 1019.5219\t MAE: 11.9404\t RMSE: 15.4832\n",
            " \n",
            "MAE: 8.6602\t RMSE: 11.4750\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 1184.0307\t MAE: 13.7935\t RMSE: 16.7791\n",
            " \n",
            "MAE: 8.6529\t RMSE: 11.4665\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 1126.0793\t MAE: 13.1495\t RMSE: 16.1240\n",
            " \n",
            "MAE: 8.6489\t RMSE: 11.4618\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 1156.1233\t MAE: 13.4853\t RMSE: 16.6534\n",
            " \n",
            "MAE: 8.6262\t RMSE: 11.4346\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 1080.4233\t MAE: 12.6340\t RMSE: 15.5147\n",
            " \n",
            "MAE: 8.6165\t RMSE: 11.4220\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 1070.0340\t MAE: 12.5190\t RMSE: 15.5511\n",
            " \n",
            "MAE: 8.5672\t RMSE: 11.3572\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 1071.4834\t MAE: 12.5318\t RMSE: 15.8001\n",
            " \n",
            "MAE: 8.5849\t RMSE: 11.3799\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 121\t Learning rate: 0.0000\t Loss: 1034.3788\t MAE: 12.1131\t RMSE: 15.5715\n",
            " \n",
            "MAE: 8.5810\t RMSE: 11.3741\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 122\t Learning rate: 0.0000\t Loss: 1096.2999\t MAE: 12.8114\t RMSE: 16.1755\n",
            " \n",
            "MAE: 8.6128\t RMSE: 11.4150\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 123\t Learning rate: 0.0000\t Loss: 1187.3000\t MAE: 13.8372\t RMSE: 16.9359\n",
            " \n",
            "MAE: 8.6139\t RMSE: 11.4156\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 124\t Learning rate: 0.0000\t Loss: 1185.5480\t MAE: 13.8147\t RMSE: 17.1779\n",
            " \n",
            "MAE: 8.6185\t RMSE: 11.4202\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 125\t Learning rate: 0.0000\t Loss: 1154.7080\t MAE: 13.4673\t RMSE: 16.4813\n",
            " \n",
            "MAE: 8.5820\t RMSE: 11.3749\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 126\t Learning rate: 0.0000\t Loss: 1127.0721\t MAE: 13.1585\t RMSE: 16.3438\n",
            " \n",
            "MAE: 8.4815\t RMSE: 11.2465\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 127\t Learning rate: 0.0000\t Loss: 984.5829\t MAE: 11.5491\t RMSE: 14.4627\n",
            " \n",
            "MAE: 8.4375\t RMSE: 11.1926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 128\t Learning rate: 0.0000\t Loss: 1094.6039\t MAE: 12.7878\t RMSE: 16.0713\n",
            " \n",
            "MAE: 8.3975\t RMSE: 11.1448\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 129\t Learning rate: 0.0000\t Loss: 988.6558\t MAE: 11.6019\t RMSE: 14.4790\n",
            " \n",
            "MAE: 8.3094\t RMSE: 11.0355\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 130\t Learning rate: 0.0000\t Loss: 1089.0001\t MAE: 12.7295\t RMSE: 15.5716\n",
            " \n",
            "MAE: 8.3227\t RMSE: 11.0527\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 131\t Learning rate: 0.0000\t Loss: 1087.8655\t MAE: 12.7105\t RMSE: 16.0708\n",
            " \n",
            "MAE: 8.3138\t RMSE: 11.0423\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 132\t Learning rate: 0.0000\t Loss: 1174.9410\t MAE: 13.6861\t RMSE: 17.0221\n",
            " \n",
            "MAE: 8.3365\t RMSE: 11.0708\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 133\t Learning rate: 0.0000\t Loss: 922.7101\t MAE: 10.8549\t RMSE: 14.0778\n",
            " \n",
            "MAE: 8.3191\t RMSE: 11.0486\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 134\t Learning rate: 0.0000\t Loss: 1142.2067\t MAE: 13.3301\t RMSE: 16.2411\n",
            " \n",
            "MAE: 8.2501\t RMSE: 10.9621\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 135\t Learning rate: 0.0000\t Loss: 1093.8633\t MAE: 12.7809\t RMSE: 16.3939\n",
            " \n",
            "MAE: 8.2599\t RMSE: 10.9776\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 136\t Learning rate: 0.0000\t Loss: 1119.9345\t MAE: 13.0736\t RMSE: 16.1754\n",
            " \n",
            "MAE: 8.2156\t RMSE: 10.9013\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 137\t Learning rate: 0.0000\t Loss: 1128.7774\t MAE: 13.1779\t RMSE: 16.1448\n",
            " \n",
            "MAE: 8.2157\t RMSE: 10.8859\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 138\t Learning rate: 0.0000\t Loss: 1073.0207\t MAE: 12.5474\t RMSE: 15.9177\n",
            " \n",
            "MAE: 8.2335\t RMSE: 10.9046\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 139\t Learning rate: 0.0000\t Loss: 1103.3953\t MAE: 12.8907\t RMSE: 15.6984\n",
            " \n",
            "MAE: 8.2090\t RMSE: 10.8119\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 140\t Learning rate: 0.0000\t Loss: 1014.1209\t MAE: 11.8879\t RMSE: 15.2509\n",
            " \n",
            "MAE: 8.2295\t RMSE: 10.8387\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 141\t Learning rate: 0.0000\t Loss: 1018.6530\t MAE: 11.9339\t RMSE: 15.1911\n",
            " \n",
            "MAE: 8.2255\t RMSE: 10.7968\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 142\t Learning rate: 0.0000\t Loss: 1001.9287\t MAE: 11.7440\t RMSE: 14.7364\n",
            " \n",
            "MAE: 8.2321\t RMSE: 10.7850\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 143\t Learning rate: 0.0000\t Loss: 993.3719\t MAE: 11.6564\t RMSE: 14.9807\n",
            " \n",
            "MAE: 8.2642\t RMSE: 10.8330\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 144\t Learning rate: 0.0000\t Loss: 1038.1142\t MAE: 12.1596\t RMSE: 15.7332\n",
            " \n",
            "MAE: 8.2833\t RMSE: 10.8504\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 145\t Learning rate: 0.0000\t Loss: 1117.6241\t MAE: 13.0516\t RMSE: 16.3809\n",
            " \n",
            "MAE: 8.3150\t RMSE: 10.8959\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 146\t Learning rate: 0.0000\t Loss: 996.9190\t MAE: 11.6867\t RMSE: 15.2656\n",
            " \n",
            "MAE: 8.3263\t RMSE: 10.8754\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 147\t Learning rate: 0.0000\t Loss: 1004.9668\t MAE: 11.7774\t RMSE: 15.0837\n",
            " \n",
            "MAE: 8.3619\t RMSE: 10.9402\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 148\t Learning rate: 0.0000\t Loss: 1078.4737\t MAE: 12.6114\t RMSE: 15.3574\n",
            " \n",
            "MAE: 8.3961\t RMSE: 10.9557\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 149\t Learning rate: 0.0000\t Loss: 1054.9325\t MAE: 12.3458\t RMSE: 15.8480\n",
            " \n",
            "MAE: 8.4456\t RMSE: 10.9811\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 150\t Learning rate: 0.0000\t Loss: 1030.3835\t MAE: 12.0684\t RMSE: 14.7581\n",
            " \n",
            "MAE: 8.5064\t RMSE: 10.9457\n",
            "\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "for fold in range(3):\n",
        "    test_dep_idxs_tmp = dep_idxs[fold*10:(fold+1)*10]\n",
        "    test_non_idxs = non_idxs[fold*44:(fold+1)*44]\n",
        "    train_dep_idxs_tmp = list(set(dep_idxs) - set(test_dep_idxs_tmp))\n",
        "    train_non_idxs = list(set(non_idxs) - set(test_non_idxs))\n",
        "\n",
        "    # training data augmentation\n",
        "    train_dep_idxs = []\n",
        "    for (i, idx) in enumerate(train_dep_idxs_tmp):\n",
        "        feat = text_features[idx]\n",
        "        if i < 14:\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "                text_targets = np.hstack((text_targets, text_targets[idx]))\n",
        "                train_dep_idxs.append(len(text_features)-1)\n",
        "        else:\n",
        "            train_dep_idxs.append(idx)\n",
        "\n",
        "    # test data augmentation\n",
        "    # test_dep_idxs = []\n",
        "    # for idx in test_dep_idxs_tmp:\n",
        "    #     feat = text_features[idx]\n",
        "    #     for i in itertools.permutations(feat, feat.shape[0]):\n",
        "    #         text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "    #         text_targets = np.hstack((text_targets, text_targets[idx]))\n",
        "    #         test_dep_idxs.append(len(text_features)-1)\n",
        "    test_dep_idxs = test_dep_idxs_tmp\n",
        "    model = TextBiLSTM(config)\n",
        "\n",
        "    if config['cuda']:\n",
        "        model = model.cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    # criterion = FocalLoss(class_num=2)\n",
        "    min_mae = 100\n",
        "    min_rmse = 100\n",
        "    train_mae = 100\n",
        "\n",
        "\n",
        "    for ep in range(1, config['epochs']):\n",
        "        train_mae = train(ep)\n",
        "        tloss = evaluate(fold, model, train_mae)\n",
        "\n",
        "# ============== prep ==============\n",
        "# X_test = np.squeeze(np.load(os.path.join(prefix, 'Features/Audio/val_samples_reg_avid256.npz'))['arr_0'], axis=2)\n",
        "# Y_test = np.load(os.path.join(prefix, 'Features/Audio/val_labels_reg_avid256.npz'))['arr_0']\n",
        "# ============== prep ==============\n",
        "\n",
        "\n",
        "# ============== SVM ==============\n",
        "\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = text_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = text_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = SVR(kernel='linear', gamma='auto')\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "#     # break\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# ============== SVM ==============\n",
        "\n",
        "# # ============== DT ==============\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = text_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = text_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = DecisionTreeRegressor(max_depth=100, random_state=0, criterion=\"mse\")\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# # ============== DT ==============\n",
        "\n",
        "# # ============== RF ==============\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = text_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = text_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = RandomForestRegressor(max_depth=100, random_state=0, criterion=\"mse\")\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# # ============== RF ==============\n",
        "\n",
        "# ============== ada ==============\n",
        "# from sklearn.ensemble import AdaBoostRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = text_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = text_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = AdaBoostRegressor(n_estimators=50)\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# ============== ada ==============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV3q-M1aszRM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u01eJODMszTZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEXiIOAmszVX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
