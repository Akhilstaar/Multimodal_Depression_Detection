{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_SWu2GzN4-sg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7TQMPxm_4-xc"
      },
      "outputs": [],
      "source": [
        "prefix = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "\n",
        "audio_features = np.squeeze(np.load(os.path.join(prefix, './Features/AudioWhole/whole_samples_reg_256.npz'))['arr_0'], axis=2)\n",
        "audio_targets = np.load(os.path.join(prefix, './Features/AudioWhole/whole_labels_reg_256.npz'))['arr_0']\n",
        "\n",
        "## No need to generate randomly everytime, save it and reuse instead.\n",
        "audio_dep_idxs = np.where(audio_targets >= 53)[0]\n",
        "audio_non_idxs = np.where(audio_targets < 53)[0]\n",
        "# dep_orders = random.sample(range(len(audio_dep_idxs)), len(audio_dep_idxs))\n",
        "# non_orders = random.sample(range(len(audio_non_idxs)), len(audio_non_idxs))\n",
        "# dep_idxs = audio_dep_idxs[dep_orders]\n",
        "# non_idxs = audio_non_idxs[non_orders]\n",
        "# np.save(os.path.join(prefix, './Features/AudioWhole/dep_idxs'), dep_idxs)\n",
        "# np.save(os.path.join(prefix, './Features/AudioWhole/non_idxs'), non_idxs)\n",
        "dep_idxs = np.load(os.path.join(prefix, './Features/AudioWhole/dep_idxs.npy'), allow_pickle=True)\n",
        "non_idxs = np.load(os.path.join(prefix, './Features/AudioWhole/non_idxs.npy'), allow_pickle=True)\n",
        "\n",
        "config = {\n",
        "    'num_classes': 1,\n",
        "    'dropout': 0.5,\n",
        "    'rnn_layers': 2,\n",
        "    'embedding_size': 256,\n",
        "    'batch_size': 2,\n",
        "    'epochs': 120,\n",
        "    'learning_rate': 1e-5,\n",
        "    'hidden_dims': 256,\n",
        "    'bidirectional': False,\n",
        "    'cuda': False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YJy4It_s4-z2"
      },
      "outputs": [],
      "source": [
        "class AudioBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(AudioBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True))\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        self.lstm_net_audio = nn.GRU(self.embedding_size,\n",
        "                                self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers,\n",
        "                                dropout=self.dropout,\n",
        "                                bidirectional=self.bidirectional,\n",
        "                                batch_first=True)\n",
        "        # self.lstm_net_audio = nn.GRU(self.embedding_size, self.hidden_dims,\n",
        "        #                         num_layers=self.rnn_layers, dropout=self.dropout, batch_first=True)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(3)\n",
        "\n",
        "        # FC\n",
        "        self.fc_audio = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            nn.ReLU(),\n",
        "            # nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        #         h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        # print(atten_w.shape, m.transpose(1, 2).shape)\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm_net_audio(x)\n",
        "        # x = self.bn(x)\n",
        "        x = x.sum(dim=1)\n",
        "        out = self.fc_audio(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZyNh3akV4-2J"
      },
      "outputs": [],
      "source": [
        "def save(model, filename):\n",
        "    save_filename = '{}.pt'.format(filename)\n",
        "    torch.save(model, save_filename)\n",
        "    print('Saved as %s' % save_filename)\n",
        "\n",
        "def train(epoch):\n",
        "    global lr, train_acc\n",
        "    model.train()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    pred = np.array([])\n",
        "    X_train = audio_features[train_dep_idxs+train_non_idxs]\n",
        "    Y_train = audio_targets[train_dep_idxs+train_non_idxs]\n",
        "    for i in range(0, X_train.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_train.shape[0]:\n",
        "            x, y = X_train[i:], Y_train[i:]\n",
        "        else:\n",
        "            x, y = X_train[i:(i + config['batch_size'])], Y_train[i:(\n",
        "                i + config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(y)).type(torch.FloatTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y.view_as(output))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_idx += 1\n",
        "        pred = np.hstack((pred, output.flatten().detach().numpy()))\n",
        "        total_loss += loss.item()\n",
        "    train_mae = mean_absolute_error(Y_train, pred)\n",
        "\n",
        "    print('Train Epoch: {:2d}\\t Learning rate: {:.4f}\\t Loss: {:.4f}\\t MAE: {:.4f}\\t RMSE: {:.4f}\\n '\n",
        "        .format(epoch + 1, config['learning_rate'], total_loss, train_mae, \\\n",
        "            np.sqrt(mean_squared_error(Y_train, pred))))\n",
        "    return train_mae\n",
        "\n",
        "\n",
        "def evaluate(fold, model, train_mae):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    global min_mae, min_rmse, test_dep_idxs, test_non_idxs\n",
        "    pred = np.array([])\n",
        "    X_test = audio_features[list(test_dep_idxs)+list(test_non_idxs)]\n",
        "    Y_test = audio_targets[list(test_dep_idxs)+list(test_non_idxs)]\n",
        "    with torch.no_grad():\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(X_test).type(torch.FloatTensor), requires_grad=True).cuda(),\\\n",
        "                Variable(torch.from_numpy(Y_test)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(X_test).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(Y_test)).type(torch.FloatTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y.view_as(output))\n",
        "        total_loss += loss.item()\n",
        "        pred = output.flatten().detach().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(Y_test, pred)\n",
        "        rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "\n",
        "        print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "        print('='*89)\n",
        "\n",
        "        if mae <= min_mae and mae < 8.5 and train_mae < 13:\n",
        "            min_mae = mae\n",
        "            min_rmse = rmse\n",
        "            mode = 'bi' if config['bidirectional'] else 'norm'\n",
        "            mode ='gru'\n",
        "            save(model, '../Model/Regression/Audio{}/{}_vlad{}_{}_{:.2f}'.format(fold+1,mode, config['embedding_size'], config['hidden_dims'], min_mae))\n",
        "            print('*' * 64)\n",
        "            print('model saved: mae: {}\\t rmse: {}'.format(min_mae, min_rmse))\n",
        "            print('*' * 64)\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bkn9eTyW4-4s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJn2C9754-u-",
        "outputId": "560bc517-20b6-48d7-9fca-5ed317d0820b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4510.8123\t MAE: 50.6833\t RMSE: 51.8116\n",
            " \n",
            "MAE: 46.2545\t RMSE: 47.6102\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4506.2614\t MAE: 50.6322\t RMSE: 51.7628\n",
            " \n",
            "MAE: 46.1972\t RMSE: 47.5547\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4501.2304\t MAE: 50.5756\t RMSE: 51.7058\n",
            " \n",
            "MAE: 46.1363\t RMSE: 47.4958\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4495.5054\t MAE: 50.5113\t RMSE: 51.6414\n",
            " \n",
            "MAE: 46.0689\t RMSE: 47.4305\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4489.6026\t MAE: 50.4450\t RMSE: 51.5786\n",
            " \n",
            "MAE: 45.9918\t RMSE: 47.3558\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4482.0718\t MAE: 50.3604\t RMSE: 51.4966\n",
            " \n",
            "MAE: 45.9016\t RMSE: 47.2684\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4472.1573\t MAE: 50.2490\t RMSE: 51.3890\n",
            " \n",
            "MAE: 45.7914\t RMSE: 47.1616\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4461.3926\t MAE: 50.1280\t RMSE: 51.2703\n",
            " \n",
            "MAE: 45.6560\t RMSE: 47.0305\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 4446.9024\t MAE: 49.9652\t RMSE: 51.1104\n",
            " \n",
            "MAE: 45.4827\t RMSE: 46.8626\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 4428.1278\t MAE: 49.7542\t RMSE: 50.9074\n",
            " \n",
            "MAE: 45.2593\t RMSE: 46.6463\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 4406.6234\t MAE: 49.5126\t RMSE: 50.6696\n",
            " \n",
            "MAE: 44.9658\t RMSE: 46.3622\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 4372.8241\t MAE: 49.1329\t RMSE: 50.3043\n",
            " \n",
            "MAE: 44.5664\t RMSE: 45.9757\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 4331.5439\t MAE: 48.6690\t RMSE: 49.8525\n",
            " \n",
            "MAE: 44.0215\t RMSE: 45.4489\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 4261.5827\t MAE: 47.8830\t RMSE: 49.0849\n",
            " \n",
            "MAE: 43.2174\t RMSE: 44.6729\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 4157.5490\t MAE: 46.7140\t RMSE: 47.9825\n",
            " \n",
            "MAE: 42.0137\t RMSE: 43.5139\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 4006.2190\t MAE: 45.0137\t RMSE: 46.2994\n",
            " \n",
            "MAE: 40.1731\t RMSE: 41.7481\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 3776.0493\t MAE: 42.4275\t RMSE: 43.8196\n",
            " \n",
            "MAE: 37.3535\t RMSE: 39.0610\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 3403.9699\t MAE: 38.2469\t RMSE: 39.7892\n",
            " \n",
            "MAE: 32.9795\t RMSE: 34.9414\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 2867.4303\t MAE: 32.2183\t RMSE: 34.1444\n",
            " \n",
            "MAE: 26.8866\t RMSE: 29.3359\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 2209.5431\t MAE: 24.8263\t RMSE: 27.2124\n",
            " \n",
            "MAE: 19.5969\t RMSE: 22.9511\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1597.4448\t MAE: 17.9488\t RMSE: 21.0241\n",
            " \n",
            "MAE: 13.9447\t RMSE: 17.7665\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1099.6396\t MAE: 12.3555\t RMSE: 14.8909\n",
            " \n",
            "MAE: 10.3795\t RMSE: 14.2524\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 888.9279\t MAE: 9.9880\t RMSE: 12.2337\n",
            " \n",
            "MAE: 9.4957\t RMSE: 12.9761\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 813.0000\t MAE: 9.1348\t RMSE: 11.2086\n",
            " \n",
            "MAE: 9.3972\t RMSE: 12.6578\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 794.2466\t MAE: 8.9241\t RMSE: 11.0328\n",
            " \n",
            "MAE: 9.3255\t RMSE: 12.4009\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 752.0583\t MAE: 8.4501\t RMSE: 10.7120\n",
            " \n",
            "MAE: 9.3321\t RMSE: 12.3999\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 816.8164\t MAE: 9.1777\t RMSE: 11.5837\n",
            " \n",
            "MAE: 9.3364\t RMSE: 12.3484\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 747.5952\t MAE: 8.3999\t RMSE: 10.7824\n",
            " \n",
            "MAE: 9.3552\t RMSE: 12.3343\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 831.3998\t MAE: 9.3416\t RMSE: 11.4910\n",
            " \n",
            "MAE: 9.3511\t RMSE: 12.3120\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 710.2774\t MAE: 7.9806\t RMSE: 10.1408\n",
            " \n",
            "MAE: 9.3692\t RMSE: 12.3180\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 713.0278\t MAE: 8.0115\t RMSE: 10.2546\n",
            " \n",
            "MAE: 9.4295\t RMSE: 12.3459\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 768.1054\t MAE: 8.6304\t RMSE: 10.7409\n",
            " \n",
            "MAE: 9.4717\t RMSE: 12.3529\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 725.7769\t MAE: 8.1548\t RMSE: 10.2973\n",
            " \n",
            "MAE: 9.4567\t RMSE: 12.3427\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 695.1654\t MAE: 7.8108\t RMSE: 9.9880\n",
            " \n",
            "MAE: 9.4555\t RMSE: 12.3667\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 680.6290\t MAE: 7.6475\t RMSE: 9.4538\n",
            " \n",
            "MAE: 9.4595\t RMSE: 12.3610\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 727.7151\t MAE: 8.1766\t RMSE: 10.3847\n",
            " \n",
            "MAE: 9.4844\t RMSE: 12.3616\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 703.9939\t MAE: 7.9100\t RMSE: 10.1680\n",
            " \n",
            "MAE: 9.4667\t RMSE: 12.3662\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 710.5363\t MAE: 7.9836\t RMSE: 10.1864\n",
            " \n",
            "MAE: 9.5042\t RMSE: 12.3456\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 685.0528\t MAE: 7.6972\t RMSE: 9.6192\n",
            " \n",
            "MAE: 9.4959\t RMSE: 12.3678\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 759.9375\t MAE: 8.5386\t RMSE: 10.4867\n",
            " \n",
            "MAE: 9.5398\t RMSE: 12.3505\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 643.1377\t MAE: 7.2263\t RMSE: 9.3046\n",
            " \n",
            "MAE: 9.5644\t RMSE: 12.3544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 611.3555\t MAE: 6.8692\t RMSE: 8.8523\n",
            " \n",
            "MAE: 9.5854\t RMSE: 12.3667\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 667.7237\t MAE: 7.5025\t RMSE: 9.2727\n",
            " \n",
            "MAE: 9.5733\t RMSE: 12.3654\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 704.7662\t MAE: 7.9187\t RMSE: 10.0650\n",
            " \n",
            "MAE: 9.5930\t RMSE: 12.3786\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 635.3967\t MAE: 7.1393\t RMSE: 9.1133\n",
            " \n",
            "MAE: 9.5930\t RMSE: 12.3593\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 646.2850\t MAE: 7.2616\t RMSE: 9.2073\n",
            " \n",
            "MAE: 9.5973\t RMSE: 12.3737\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 654.7243\t MAE: 7.3565\t RMSE: 9.3535\n",
            " \n",
            "MAE: 9.5691\t RMSE: 12.3714\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 699.2558\t MAE: 7.8568\t RMSE: 9.6306\n",
            " \n",
            "MAE: 9.5867\t RMSE: 12.3744\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 612.4117\t MAE: 6.8810\t RMSE: 8.9026\n",
            " \n",
            "MAE: 9.6087\t RMSE: 12.3621\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 669.8277\t MAE: 7.5262\t RMSE: 9.5141\n",
            " \n",
            "MAE: 9.6301\t RMSE: 12.3765\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 612.3588\t MAE: 6.8804\t RMSE: 8.9236\n",
            " \n",
            "MAE: 9.6871\t RMSE: 12.4012\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 630.5438\t MAE: 7.0848\t RMSE: 9.2986\n",
            " \n",
            "MAE: 9.6891\t RMSE: 12.4003\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 665.4271\t MAE: 7.4767\t RMSE: 9.5777\n",
            " \n",
            "MAE: 9.6684\t RMSE: 12.3939\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 624.0613\t MAE: 7.0119\t RMSE: 8.7283\n",
            " \n",
            "MAE: 9.6685\t RMSE: 12.4087\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 643.0921\t MAE: 7.2258\t RMSE: 9.1988\n",
            " \n",
            "MAE: 9.6662\t RMSE: 12.4072\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 681.8141\t MAE: 7.6608\t RMSE: 9.8099\n",
            " \n",
            "MAE: 9.6848\t RMSE: 12.3986\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 650.8754\t MAE: 7.3132\t RMSE: 9.1898\n",
            " \n",
            "MAE: 9.6639\t RMSE: 12.3940\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 620.7028\t MAE: 6.9742\t RMSE: 8.8230\n",
            " \n",
            "MAE: 9.6424\t RMSE: 12.4081\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 564.3066\t MAE: 6.3405\t RMSE: 8.5977\n",
            " \n",
            "MAE: 9.6910\t RMSE: 12.4143\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 657.6607\t MAE: 7.3894\t RMSE: 9.2047\n",
            " \n",
            "MAE: 9.7135\t RMSE: 12.4160\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 602.4650\t MAE: 6.7693\t RMSE: 8.8041\n",
            " \n",
            "MAE: 9.7254\t RMSE: 12.4302\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 569.9875\t MAE: 6.4044\t RMSE: 8.3751\n",
            " \n",
            "MAE: 9.7700\t RMSE: 12.4599\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 592.7416\t MAE: 6.6600\t RMSE: 8.5835\n",
            " \n",
            "MAE: 9.7934\t RMSE: 12.4765\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 639.4678\t MAE: 7.1850\t RMSE: 9.1348\n",
            " \n",
            "MAE: 9.7591\t RMSE: 12.4668\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 585.7660\t MAE: 6.5816\t RMSE: 8.5160\n",
            " \n",
            "MAE: 9.7627\t RMSE: 12.4695\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 604.7926\t MAE: 6.7954\t RMSE: 8.7560\n",
            " \n",
            "MAE: 9.7627\t RMSE: 12.4727\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 566.8727\t MAE: 6.3694\t RMSE: 8.3699\n",
            " \n",
            "MAE: 9.7795\t RMSE: 12.4801\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 609.3317\t MAE: 6.8464\t RMSE: 8.9062\n",
            " \n",
            "MAE: 9.7528\t RMSE: 12.4793\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 603.3567\t MAE: 6.7793\t RMSE: 8.4059\n",
            " \n",
            "MAE: 9.7754\t RMSE: 12.4864\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 593.5049\t MAE: 6.6686\t RMSE: 8.4610\n",
            " \n",
            "MAE: 9.8081\t RMSE: 12.4995\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 559.8392\t MAE: 6.2903\t RMSE: 7.8062\n",
            " \n",
            "MAE: 9.7967\t RMSE: 12.5149\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 557.1412\t MAE: 6.2600\t RMSE: 8.0510\n",
            " \n",
            "MAE: 9.8033\t RMSE: 12.5087\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 562.0220\t MAE: 6.3149\t RMSE: 8.3581\n",
            " \n",
            "MAE: 9.8057\t RMSE: 12.5244\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 542.5992\t MAE: 6.0966\t RMSE: 7.6733\n",
            " \n",
            "MAE: 9.8110\t RMSE: 12.4974\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 602.5207\t MAE: 6.7699\t RMSE: 8.6721\n",
            " \n",
            "MAE: 9.7893\t RMSE: 12.4823\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 561.0776\t MAE: 6.3042\t RMSE: 8.3068\n",
            " \n",
            "MAE: 9.8054\t RMSE: 12.4963\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 623.1051\t MAE: 7.0012\t RMSE: 9.0555\n",
            " \n",
            "MAE: 9.8475\t RMSE: 12.5100\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 513.1720\t MAE: 5.7660\t RMSE: 7.2261\n",
            " \n",
            "MAE: 9.8365\t RMSE: 12.5003\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 512.1174\t MAE: 5.7541\t RMSE: 7.2554\n",
            " \n",
            "MAE: 9.8275\t RMSE: 12.4801\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 532.4750\t MAE: 5.9829\t RMSE: 7.7442\n",
            " \n",
            "MAE: 9.8509\t RMSE: 12.5033\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 489.6406\t MAE: 5.5016\t RMSE: 6.9024\n",
            " \n",
            "MAE: 9.8573\t RMSE: 12.5116\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 559.8500\t MAE: 6.2904\t RMSE: 8.2265\n",
            " \n",
            "MAE: 9.8651\t RMSE: 12.5115\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 582.6193\t MAE: 6.5463\t RMSE: 8.5135\n",
            " \n",
            "MAE: 9.8244\t RMSE: 12.5050\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 580.8406\t MAE: 6.5263\t RMSE: 8.1212\n",
            " \n",
            "MAE: 9.8280\t RMSE: 12.4978\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 571.3853\t MAE: 6.4201\t RMSE: 8.2110\n",
            " \n",
            "MAE: 9.8278\t RMSE: 12.5040\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 557.1584\t MAE: 6.2602\t RMSE: 7.9406\n",
            " \n",
            "MAE: 9.8367\t RMSE: 12.5193\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 574.7335\t MAE: 6.4577\t RMSE: 8.2843\n",
            " \n",
            "MAE: 9.8085\t RMSE: 12.5055\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 557.3371\t MAE: 6.2622\t RMSE: 7.8121\n",
            " \n",
            "MAE: 9.7990\t RMSE: 12.5123\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 564.7810\t MAE: 6.3459\t RMSE: 8.2225\n",
            " \n",
            "MAE: 9.8615\t RMSE: 12.5330\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 549.7639\t MAE: 6.1771\t RMSE: 8.0854\n",
            " \n",
            "MAE: 9.8762\t RMSE: 12.5395\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 574.4023\t MAE: 6.4540\t RMSE: 8.0837\n",
            " \n",
            "MAE: 9.8535\t RMSE: 12.5466\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 489.2322\t MAE: 5.4970\t RMSE: 7.4338\n",
            " \n",
            "MAE: 9.8370\t RMSE: 12.5682\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 540.0049\t MAE: 6.0675\t RMSE: 7.5994\n",
            " \n",
            "MAE: 9.8490\t RMSE: 12.5889\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 483.7471\t MAE: 5.4354\t RMSE: 7.4683\n",
            " \n",
            "MAE: 9.8368\t RMSE: 12.5696\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 543.8463\t MAE: 6.1106\t RMSE: 7.6370\n",
            " \n",
            "MAE: 9.8853\t RMSE: 12.5598\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 498.5926\t MAE: 5.6022\t RMSE: 7.5404\n",
            " \n",
            "MAE: 9.9636\t RMSE: 12.5718\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 583.4091\t MAE: 6.5552\t RMSE: 8.4340\n",
            " \n",
            "MAE: 9.9523\t RMSE: 12.5642\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 541.4339\t MAE: 6.0835\t RMSE: 7.8635\n",
            " \n",
            "MAE: 9.9258\t RMSE: 12.5627\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 538.9227\t MAE: 6.0553\t RMSE: 8.2526\n",
            " \n",
            "MAE: 9.9212\t RMSE: 12.5573\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 563.0819\t MAE: 6.3268\t RMSE: 8.0041\n",
            " \n",
            "MAE: 9.8979\t RMSE: 12.5417\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 509.9360\t MAE: 5.7296\t RMSE: 7.2238\n",
            " \n",
            "MAE: 9.8727\t RMSE: 12.5382\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 555.7544\t MAE: 6.2444\t RMSE: 7.9450\n",
            " \n",
            "MAE: 9.9101\t RMSE: 12.5553\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 508.8078\t MAE: 5.7169\t RMSE: 7.6136\n",
            " \n",
            "MAE: 9.9502\t RMSE: 12.5737\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 535.1433\t MAE: 6.0128\t RMSE: 7.5115\n",
            " \n",
            "MAE: 9.9647\t RMSE: 12.5879\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 558.9511\t MAE: 6.2803\t RMSE: 8.4446\n",
            " \n",
            "MAE: 9.9343\t RMSE: 12.5930\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 515.4698\t MAE: 5.7918\t RMSE: 7.6392\n",
            " \n",
            "MAE: 9.9457\t RMSE: 12.5765\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 531.5696\t MAE: 5.9727\t RMSE: 7.7469\n",
            " \n",
            "MAE: 9.9603\t RMSE: 12.5743\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 523.9272\t MAE: 5.8868\t RMSE: 7.8989\n",
            " \n",
            "MAE: 9.9595\t RMSE: 12.5721\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 528.7980\t MAE: 5.9416\t RMSE: 7.8483\n",
            " \n",
            "MAE: 10.0025\t RMSE: 12.5734\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 500.8650\t MAE: 5.6277\t RMSE: 7.1704\n",
            " \n",
            "MAE: 9.9467\t RMSE: 12.5510\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 523.7200\t MAE: 5.8845\t RMSE: 7.6126\n",
            " \n",
            "MAE: 9.9728\t RMSE: 12.5570\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 490.2193\t MAE: 5.5081\t RMSE: 7.0967\n",
            " \n",
            "MAE: 9.9297\t RMSE: 12.5607\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 543.4382\t MAE: 6.1060\t RMSE: 7.9127\n",
            " \n",
            "MAE: 9.9382\t RMSE: 12.5379\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 491.9210\t MAE: 5.5272\t RMSE: 6.9785\n",
            " \n",
            "MAE: 9.9323\t RMSE: 12.5341\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 503.5750\t MAE: 5.6581\t RMSE: 7.4596\n",
            " \n",
            "MAE: 9.9358\t RMSE: 12.5198\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 551.2402\t MAE: 6.1937\t RMSE: 7.8185\n",
            " \n",
            "MAE: 9.9826\t RMSE: 12.5614\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 513.4234\t MAE: 5.7688\t RMSE: 7.4927\n",
            " \n",
            "MAE: 9.9906\t RMSE: 12.5722\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 475.6915\t MAE: 5.3448\t RMSE: 7.1037\n",
            " \n",
            "MAE: 10.0132\t RMSE: 12.5981\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 497.6936\t MAE: 5.5921\t RMSE: 7.4170\n",
            " \n",
            "MAE: 9.9972\t RMSE: 12.5969\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4710.0419\t MAE: 52.9218\t RMSE: 54.5218\n",
            " \n",
            "MAE: 44.6186\t RMSE: 45.6273\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4708.1811\t MAE: 52.9009\t RMSE: 54.5028\n",
            " \n",
            "MAE: 44.5743\t RMSE: 45.5840\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4704.4131\t MAE: 52.8586\t RMSE: 54.4629\n",
            " \n",
            "MAE: 44.5210\t RMSE: 45.5318\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4698.9552\t MAE: 52.7972\t RMSE: 54.4030\n",
            " \n",
            "MAE: 44.4593\t RMSE: 45.4713\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4693.2169\t MAE: 52.7328\t RMSE: 54.3395\n",
            " \n",
            "MAE: 44.3901\t RMSE: 45.4035\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4685.5030\t MAE: 52.6461\t RMSE: 54.2559\n",
            " \n",
            "MAE: 44.3085\t RMSE: 45.3234\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4678.4544\t MAE: 52.5669\t RMSE: 54.1781\n",
            " \n",
            "MAE: 44.2096\t RMSE: 45.2265\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4667.5414\t MAE: 52.4443\t RMSE: 54.0651\n",
            " \n",
            "MAE: 44.0843\t RMSE: 45.1036\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 4654.3537\t MAE: 52.2961\t RMSE: 53.9248\n",
            " \n",
            "MAE: 43.9218\t RMSE: 44.9439\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 4637.9903\t MAE: 52.1123\t RMSE: 53.7387\n",
            " \n",
            "MAE: 43.7102\t RMSE: 44.7362\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 4612.7407\t MAE: 51.8285\t RMSE: 53.4720\n",
            " \n",
            "MAE: 43.4234\t RMSE: 44.4546\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 4581.6945\t MAE: 51.4797\t RMSE: 53.1367\n",
            " \n",
            "MAE: 43.0303\t RMSE: 44.0688\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 4529.8038\t MAE: 50.8967\t RMSE: 52.5689\n",
            " \n",
            "MAE: 42.4599\t RMSE: 43.5092\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 4463.7088\t MAE: 50.1540\t RMSE: 51.8470\n",
            " \n",
            "MAE: 41.6367\t RMSE: 42.7020\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 4353.3984\t MAE: 48.9146\t RMSE: 50.6636\n",
            " \n",
            "MAE: 40.3861\t RMSE: 41.4771\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 4194.1551\t MAE: 47.1253\t RMSE: 48.9779\n",
            " \n",
            "MAE: 38.4581\t RMSE: 39.5934\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 3919.9402\t MAE: 44.0443\t RMSE: 46.0150\n",
            " \n",
            "MAE: 35.3539\t RMSE: 36.5741\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 3509.4648\t MAE: 39.4322\t RMSE: 41.6389\n",
            " \n",
            "MAE: 30.6218\t RMSE: 32.0158\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 2947.1320\t MAE: 33.1138\t RMSE: 35.8189\n",
            " \n",
            "MAE: 24.2536\t RMSE: 26.0063\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 2164.4310\t MAE: 24.3194\t RMSE: 27.9116\n",
            " \n",
            "MAE: 16.9818\t RMSE: 19.2544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1542.5342\t MAE: 17.3318\t RMSE: 21.2615\n",
            " \n",
            "MAE: 11.4373\t RMSE: 13.8689\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1176.7037\t MAE: 13.2214\t RMSE: 17.1672\n",
            " \n",
            "MAE: 9.4001\t RMSE: 11.4257\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 994.4900\t MAE: 11.1740\t RMSE: 14.2804\n",
            " \n",
            "MAE: 8.5726\t RMSE: 10.2818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 947.1676\t MAE: 10.6423\t RMSE: 13.6497\n",
            " \n",
            "MAE: 8.2793\t RMSE: 9.9164\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio2/gru_vlad256_256_8.28.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.27934095594618\t rmse: 9.916436595260356\n",
            "****************************************************************\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 930.3308\t MAE: 10.4532\t RMSE: 13.2167\n",
            " \n",
            "MAE: 8.1495\t RMSE: 9.8048\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio2/gru_vlad256_256_8.15.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.149541289718062\t rmse: 9.804805933590204\n",
            "****************************************************************\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 891.5516\t MAE: 10.0174\t RMSE: 12.8720\n",
            " \n",
            "MAE: 8.1514\t RMSE: 9.8045\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 869.4708\t MAE: 9.7693\t RMSE: 12.5340\n",
            " \n",
            "MAE: 8.1781\t RMSE: 9.8247\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 882.5876\t MAE: 9.9167\t RMSE: 12.7174\n",
            " \n",
            "MAE: 8.1728\t RMSE: 9.8155\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 825.9662\t MAE: 9.2805\t RMSE: 12.1926\n",
            " \n",
            "MAE: 8.1480\t RMSE: 9.8026\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio2/gru_vlad256_256_8.15.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.148033848515263\t rmse: 9.802590729723681\n",
            "****************************************************************\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 861.6936\t MAE: 9.6820\t RMSE: 12.6036\n",
            " \n",
            "MAE: 8.1513\t RMSE: 9.8318\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 801.2748\t MAE: 9.0031\t RMSE: 11.4899\n",
            " \n",
            "MAE: 8.1723\t RMSE: 9.8597\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 830.2965\t MAE: 9.3292\t RMSE: 11.8032\n",
            " \n",
            "MAE: 8.2017\t RMSE: 9.8780\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 839.4104\t MAE: 9.4316\t RMSE: 12.0632\n",
            " \n",
            "MAE: 8.2166\t RMSE: 9.8950\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 819.7818\t MAE: 9.2110\t RMSE: 11.5025\n",
            " \n",
            "MAE: 8.2570\t RMSE: 9.9174\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 798.6095\t MAE: 8.9731\t RMSE: 11.5180\n",
            " \n",
            "MAE: 8.2500\t RMSE: 9.9429\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 782.7993\t MAE: 8.7955\t RMSE: 11.5327\n",
            " \n",
            "MAE: 8.2852\t RMSE: 9.9621\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 851.0214\t MAE: 9.5620\t RMSE: 12.1694\n",
            " \n",
            "MAE: 8.3571\t RMSE: 9.9879\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 754.1532\t MAE: 8.4736\t RMSE: 11.2322\n",
            " \n",
            "MAE: 8.4045\t RMSE: 10.0299\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 770.2828\t MAE: 8.6549\t RMSE: 11.3647\n",
            " \n",
            "MAE: 8.4047\t RMSE: 10.0321\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 826.7082\t MAE: 9.2889\t RMSE: 12.0816\n",
            " \n",
            "MAE: 8.4145\t RMSE: 10.0486\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 701.2036\t MAE: 7.8787\t RMSE: 10.6719\n",
            " \n",
            "MAE: 8.3789\t RMSE: 10.0504\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 721.7114\t MAE: 8.1091\t RMSE: 10.8415\n",
            " \n",
            "MAE: 8.4081\t RMSE: 10.0716\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 790.8335\t MAE: 8.8858\t RMSE: 11.6432\n",
            " \n",
            "MAE: 8.4045\t RMSE: 10.0881\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 780.7290\t MAE: 8.7722\t RMSE: 11.6889\n",
            " \n",
            "MAE: 8.4659\t RMSE: 10.1268\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 745.9731\t MAE: 8.3817\t RMSE: 10.8878\n",
            " \n",
            "MAE: 8.4763\t RMSE: 10.1537\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 758.0331\t MAE: 8.5172\t RMSE: 11.0678\n",
            " \n",
            "MAE: 8.4775\t RMSE: 10.1627\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 696.8750\t MAE: 7.8301\t RMSE: 10.1519\n",
            " \n",
            "MAE: 8.5092\t RMSE: 10.1863\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 727.7504\t MAE: 8.1770\t RMSE: 10.9341\n",
            " \n",
            "MAE: 8.5222\t RMSE: 10.2072\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 779.1472\t MAE: 8.7545\t RMSE: 11.6978\n",
            " \n",
            "MAE: 8.5822\t RMSE: 10.2447\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 720.8987\t MAE: 8.1000\t RMSE: 10.4650\n",
            " \n",
            "MAE: 8.6391\t RMSE: 10.3029\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 738.7698\t MAE: 8.3008\t RMSE: 10.6186\n",
            " \n",
            "MAE: 8.6717\t RMSE: 10.3346\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 739.5723\t MAE: 8.3098\t RMSE: 11.0195\n",
            " \n",
            "MAE: 8.7217\t RMSE: 10.3965\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 723.2537\t MAE: 8.1264\t RMSE: 10.2644\n",
            " \n",
            "MAE: 8.7452\t RMSE: 10.4195\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 775.8257\t MAE: 8.7171\t RMSE: 10.9172\n",
            " \n",
            "MAE: 8.8400\t RMSE: 10.4821\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 686.0279\t MAE: 7.7082\t RMSE: 9.8148\n",
            " \n",
            "MAE: 8.7567\t RMSE: 10.4651\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 772.9277\t MAE: 8.6846\t RMSE: 11.1757\n",
            " \n",
            "MAE: 8.7997\t RMSE: 10.4975\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 663.9740\t MAE: 7.4604\t RMSE: 10.0051\n",
            " \n",
            "MAE: 8.7914\t RMSE: 10.5140\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 698.7245\t MAE: 7.8508\t RMSE: 10.2414\n",
            " \n",
            "MAE: 8.7816\t RMSE: 10.5242\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 680.5380\t MAE: 7.6465\t RMSE: 10.1393\n",
            " \n",
            "MAE: 8.7904\t RMSE: 10.5567\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 731.4437\t MAE: 8.2185\t RMSE: 10.1831\n",
            " \n",
            "MAE: 8.8070\t RMSE: 10.5866\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 684.2715\t MAE: 7.6884\t RMSE: 9.9447\n",
            " \n",
            "MAE: 8.8718\t RMSE: 10.6232\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 666.9536\t MAE: 7.4939\t RMSE: 9.8108\n",
            " \n",
            "MAE: 8.8198\t RMSE: 10.6133\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 767.4771\t MAE: 8.6233\t RMSE: 10.8687\n",
            " \n",
            "MAE: 8.8217\t RMSE: 10.6374\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 696.2003\t MAE: 7.8225\t RMSE: 10.1538\n",
            " \n",
            "MAE: 8.8518\t RMSE: 10.6723\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 642.3986\t MAE: 7.2180\t RMSE: 9.8026\n",
            " \n",
            "MAE: 8.9277\t RMSE: 10.7235\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 633.0104\t MAE: 7.1125\t RMSE: 9.3642\n",
            " \n",
            "MAE: 8.9594\t RMSE: 10.7751\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 638.3435\t MAE: 7.1724\t RMSE: 9.3275\n",
            " \n",
            "MAE: 8.9874\t RMSE: 10.7954\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 629.8657\t MAE: 7.0771\t RMSE: 9.6624\n",
            " \n",
            "MAE: 9.1145\t RMSE: 10.8698\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 726.3355\t MAE: 8.1611\t RMSE: 10.6898\n",
            " \n",
            "MAE: 9.0871\t RMSE: 10.8806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 619.1217\t MAE: 6.9564\t RMSE: 9.2454\n",
            " \n",
            "MAE: 9.1563\t RMSE: 10.9198\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 646.6812\t MAE: 7.2661\t RMSE: 9.4889\n",
            " \n",
            "MAE: 9.0364\t RMSE: 10.9010\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 611.1037\t MAE: 6.8663\t RMSE: 9.2541\n",
            " \n",
            "MAE: 8.9710\t RMSE: 10.9115\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 645.7339\t MAE: 7.2554\t RMSE: 9.2922\n",
            " \n",
            "MAE: 8.9753\t RMSE: 10.9143\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 602.7852\t MAE: 6.7729\t RMSE: 9.3251\n",
            " \n",
            "MAE: 9.0715\t RMSE: 10.9333\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 636.7105\t MAE: 7.1541\t RMSE: 9.2744\n",
            " \n",
            "MAE: 9.0889\t RMSE: 10.9727\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 682.3964\t MAE: 7.6674\t RMSE: 10.1324\n",
            " \n",
            "MAE: 9.2288\t RMSE: 11.0302\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 637.7777\t MAE: 7.1660\t RMSE: 9.2626\n",
            " \n",
            "MAE: 9.2667\t RMSE: 11.0611\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 679.3172\t MAE: 7.6328\t RMSE: 9.8069\n",
            " \n",
            "MAE: 9.3600\t RMSE: 11.1307\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 616.7734\t MAE: 6.9300\t RMSE: 9.4662\n",
            " \n",
            "MAE: 9.3095\t RMSE: 11.1031\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 561.8073\t MAE: 6.3124\t RMSE: 8.3321\n",
            " \n",
            "MAE: 9.2590\t RMSE: 11.0878\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 631.9936\t MAE: 7.1011\t RMSE: 9.2675\n",
            " \n",
            "MAE: 9.2338\t RMSE: 11.0916\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 628.3392\t MAE: 7.0600\t RMSE: 9.1329\n",
            " \n",
            "MAE: 9.2015\t RMSE: 11.1024\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 565.9406\t MAE: 6.3589\t RMSE: 8.4594\n",
            " \n",
            "MAE: 9.1745\t RMSE: 11.1019\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 611.9648\t MAE: 6.8760\t RMSE: 9.2814\n",
            " \n",
            "MAE: 9.1556\t RMSE: 11.1114\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 649.9377\t MAE: 7.3027\t RMSE: 9.5365\n",
            " \n",
            "MAE: 9.1380\t RMSE: 11.1119\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 593.5982\t MAE: 6.6696\t RMSE: 8.7327\n",
            " \n",
            "MAE: 9.1311\t RMSE: 11.1131\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 565.6355\t MAE: 6.3555\t RMSE: 8.5543\n",
            " \n",
            "MAE: 9.1668\t RMSE: 11.1303\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 595.8847\t MAE: 6.6953\t RMSE: 8.6488\n",
            " \n",
            "MAE: 9.2088\t RMSE: 11.1601\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 596.0577\t MAE: 6.6973\t RMSE: 9.2746\n",
            " \n",
            "MAE: 9.1912\t RMSE: 11.1592\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 611.0422\t MAE: 6.8656\t RMSE: 9.2862\n",
            " \n",
            "MAE: 9.1383\t RMSE: 11.1374\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 578.9144\t MAE: 6.5047\t RMSE: 8.6178\n",
            " \n",
            "MAE: 9.1733\t RMSE: 11.1575\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 585.6870\t MAE: 6.5808\t RMSE: 8.4653\n",
            " \n",
            "MAE: 9.1904\t RMSE: 11.1606\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 617.1766\t MAE: 6.9346\t RMSE: 8.9706\n",
            " \n",
            "MAE: 9.2772\t RMSE: 11.2134\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 625.8605\t MAE: 7.0321\t RMSE: 8.9421\n",
            " \n",
            "MAE: 9.2516\t RMSE: 11.2049\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 592.6112\t MAE: 6.6586\t RMSE: 8.5599\n",
            " \n",
            "MAE: 9.3140\t RMSE: 11.2359\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 601.2738\t MAE: 6.7559\t RMSE: 8.8238\n",
            " \n",
            "MAE: 9.1664\t RMSE: 11.2021\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 579.6322\t MAE: 6.5127\t RMSE: 8.2545\n",
            " \n",
            "MAE: 9.1493\t RMSE: 11.1859\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 566.1624\t MAE: 6.3614\t RMSE: 8.2550\n",
            " \n",
            "MAE: 9.1140\t RMSE: 11.1969\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 630.1770\t MAE: 7.0806\t RMSE: 8.8831\n",
            " \n",
            "MAE: 9.1445\t RMSE: 11.2434\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 588.1359\t MAE: 6.6083\t RMSE: 8.3512\n",
            " \n",
            "MAE: 9.0963\t RMSE: 11.2695\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 595.9084\t MAE: 6.6956\t RMSE: 8.4320\n",
            " \n",
            "MAE: 9.1128\t RMSE: 11.2589\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 557.0159\t MAE: 6.2586\t RMSE: 8.3849\n",
            " \n",
            "MAE: 9.1192\t RMSE: 11.2698\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 585.3889\t MAE: 6.5774\t RMSE: 8.3832\n",
            " \n",
            "MAE: 9.1444\t RMSE: 11.2951\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 543.1415\t MAE: 6.1027\t RMSE: 7.5494\n",
            " \n",
            "MAE: 9.2277\t RMSE: 11.3216\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 537.7941\t MAE: 6.0426\t RMSE: 7.8895\n",
            " \n",
            "MAE: 9.1596\t RMSE: 11.3245\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 597.6423\t MAE: 6.7151\t RMSE: 8.6232\n",
            " \n",
            "MAE: 9.2219\t RMSE: 11.3672\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 530.3307\t MAE: 5.9588\t RMSE: 7.8176\n",
            " \n",
            "MAE: 9.2060\t RMSE: 11.3894\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 516.9624\t MAE: 5.8086\t RMSE: 7.8557\n",
            " \n",
            "MAE: 9.2234\t RMSE: 11.3985\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 586.0903\t MAE: 6.5853\t RMSE: 8.6283\n",
            " \n",
            "MAE: 9.2090\t RMSE: 11.4322\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 587.5745\t MAE: 6.6020\t RMSE: 8.6068\n",
            " \n",
            "MAE: 9.1715\t RMSE: 11.4430\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 580.8518\t MAE: 6.5264\t RMSE: 8.6069\n",
            " \n",
            "MAE: 9.2592\t RMSE: 11.4578\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 566.9796\t MAE: 6.3706\t RMSE: 8.0904\n",
            " \n",
            "MAE: 9.2396\t RMSE: 11.4342\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 593.6877\t MAE: 6.6706\t RMSE: 8.6699\n",
            " \n",
            "MAE: 9.2061\t RMSE: 11.4351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 506.6509\t MAE: 5.6927\t RMSE: 7.5865\n",
            " \n",
            "MAE: 9.1351\t RMSE: 11.4570\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 545.7920\t MAE: 6.1325\t RMSE: 7.8275\n",
            " \n",
            "MAE: 9.3439\t RMSE: 11.5260\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 576.9576\t MAE: 6.4827\t RMSE: 8.2642\n",
            " \n",
            "MAE: 9.3521\t RMSE: 11.5501\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 527.9719\t MAE: 5.9323\t RMSE: 7.8219\n",
            " \n",
            "MAE: 9.2947\t RMSE: 11.5384\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 591.5579\t MAE: 6.6467\t RMSE: 8.2135\n",
            " \n",
            "MAE: 9.3343\t RMSE: 11.5351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 570.3565\t MAE: 6.4085\t RMSE: 8.2802\n",
            " \n",
            "MAE: 9.3090\t RMSE: 11.5307\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  2\t Learning rate: 0.0000\t Loss: 4648.9594\t MAE: 52.2355\t RMSE: 53.7730\n",
            " \n",
            "MAE: 45.9039\t RMSE: 47.0293\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\t Loss: 4644.0597\t MAE: 52.1804\t RMSE: 53.7207\n",
            " \n",
            "MAE: 45.8509\t RMSE: 46.9776\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\t Loss: 4638.8967\t MAE: 52.1224\t RMSE: 53.6656\n",
            " \n",
            "MAE: 45.7920\t RMSE: 46.9202\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\t Loss: 4633.4237\t MAE: 52.0609\t RMSE: 53.6048\n",
            " \n",
            "MAE: 45.7244\t RMSE: 46.8544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\t Loss: 4627.3068\t MAE: 51.9922\t RMSE: 53.5403\n",
            " \n",
            "MAE: 45.6453\t RMSE: 46.7772\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\t Loss: 4620.4307\t MAE: 51.9150\t RMSE: 53.4658\n",
            " \n",
            "MAE: 45.5528\t RMSE: 46.6870\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\t Loss: 4611.0894\t MAE: 51.8100\t RMSE: 53.3626\n",
            " \n",
            "MAE: 45.4403\t RMSE: 46.5773\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\t Loss: 4598.2672\t MAE: 51.6659\t RMSE: 53.2232\n",
            " \n",
            "MAE: 45.2950\t RMSE: 46.4357\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\t Loss: 4583.4095\t MAE: 51.4990\t RMSE: 53.0598\n",
            " \n",
            "MAE: 45.1116\t RMSE: 46.2568\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\t Loss: 4563.1546\t MAE: 51.2714\t RMSE: 52.8474\n",
            " \n",
            "MAE: 44.8731\t RMSE: 46.0243\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\t Loss: 4538.1269\t MAE: 50.9902\t RMSE: 52.5722\n",
            " \n",
            "MAE: 44.5553\t RMSE: 45.7143\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\t Loss: 4502.0482\t MAE: 50.5848\t RMSE: 52.1781\n",
            " \n",
            "MAE: 44.1227\t RMSE: 45.2926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\t Loss: 4448.6869\t MAE: 49.9852\t RMSE: 51.6106\n",
            " \n",
            "MAE: 43.5039\t RMSE: 44.6893\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\t Loss: 4371.1961\t MAE: 49.1146\t RMSE: 50.7769\n",
            " \n",
            "MAE: 42.5995\t RMSE: 43.8083\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\t Loss: 4263.7797\t MAE: 47.9076\t RMSE: 49.6204\n",
            " \n",
            "MAE: 41.2650\t RMSE: 42.5102\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\t Loss: 4091.0311\t MAE: 45.9666\t RMSE: 47.7677\n",
            " \n",
            "MAE: 39.2191\t RMSE: 40.5243\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\t Loss: 3829.6591\t MAE: 43.0299\t RMSE: 44.9710\n",
            " \n",
            "MAE: 36.0748\t RMSE: 37.4871\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\t Loss: 3430.0961\t MAE: 38.5404\t RMSE: 40.7856\n",
            " \n",
            "MAE: 31.3394\t RMSE: 32.9580\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\t Loss: 2847.0961\t MAE: 31.9898\t RMSE: 34.7300\n",
            " \n",
            "MAE: 24.8933\t RMSE: 26.9238\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\t Loss: 2135.0319\t MAE: 23.9891\t RMSE: 27.4540\n",
            " \n",
            "MAE: 17.9928\t RMSE: 20.4375\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\t Loss: 1566.7419\t MAE: 17.6038\t RMSE: 21.4292\n",
            " \n",
            "MAE: 12.7882\t RMSE: 15.5818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\t Loss: 1267.3170\t MAE: 14.2395\t RMSE: 17.7784\n",
            " \n",
            "MAE: 10.1853\t RMSE: 12.7801\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\t Loss: 1005.0830\t MAE: 11.2931\t RMSE: 14.3969\n",
            " \n",
            "MAE: 9.0751\t RMSE: 11.5278\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\t Loss: 989.0956\t MAE: 11.1134\t RMSE: 14.1684\n",
            " \n",
            "MAE: 8.7178\t RMSE: 11.1200\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\t Loss: 899.2337\t MAE: 10.1037\t RMSE: 12.7589\n",
            " \n",
            "MAE: 8.4290\t RMSE: 10.7560\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.43.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.429034974839952\t rmse: 10.756036344936113\n",
            "****************************************************************\n",
            "Train Epoch: 27\t Learning rate: 0.0000\t Loss: 864.9099\t MAE: 9.7181\t RMSE: 12.8650\n",
            " \n",
            "MAE: 8.3283\t RMSE: 10.6076\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.33.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.328309800889757\t rmse: 10.60762919408073\n",
            "****************************************************************\n",
            "Train Epoch: 28\t Learning rate: 0.0000\t Loss: 877.3577\t MAE: 9.8580\t RMSE: 12.8326\n",
            " \n",
            "MAE: 8.2675\t RMSE: 10.4707\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.27.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.2674560546875\t rmse: 10.470707541652128\n",
            "****************************************************************\n",
            "Train Epoch: 29\t Learning rate: 0.0000\t Loss: 881.3521\t MAE: 9.9028\t RMSE: 12.4875\n",
            " \n",
            "MAE: 8.2524\t RMSE: 10.4525\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.25.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.252367443508572\t rmse: 10.452497257112093\n",
            "****************************************************************\n",
            "Train Epoch: 30\t Learning rate: 0.0000\t Loss: 841.5020\t MAE: 9.4551\t RMSE: 12.0658\n",
            " \n",
            "MAE: 8.2445\t RMSE: 10.4225\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.24.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.24454116821289\t rmse: 10.422493042315159\n",
            "****************************************************************\n",
            "Train Epoch: 31\t Learning rate: 0.0000\t Loss: 951.5853\t MAE: 10.6920\t RMSE: 13.0886\n",
            " \n",
            "MAE: 8.2374\t RMSE: 10.4122\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.24.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.23743106700756\t rmse: 10.412164453443458\n",
            "****************************************************************\n",
            "Train Epoch: 32\t Learning rate: 0.0000\t Loss: 835.3399\t MAE: 9.3858\t RMSE: 12.1048\n",
            " \n",
            "MAE: 8.2430\t RMSE: 10.4242\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\t Loss: 807.0909\t MAE: 9.0684\t RMSE: 11.3849\n",
            " \n",
            "MAE: 8.2542\t RMSE: 10.3952\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\t Loss: 867.4143\t MAE: 9.7462\t RMSE: 12.1609\n",
            " \n",
            "MAE: 8.2462\t RMSE: 10.4128\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\t Loss: 856.1036\t MAE: 9.6191\t RMSE: 12.2799\n",
            " \n",
            "MAE: 8.2565\t RMSE: 10.4323\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\t Loss: 771.8669\t MAE: 8.6727\t RMSE: 11.2120\n",
            " \n",
            "MAE: 8.2625\t RMSE: 10.4654\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\t Loss: 861.7311\t MAE: 9.6824\t RMSE: 12.2996\n",
            " \n",
            "MAE: 8.2516\t RMSE: 10.4915\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\t Loss: 795.1016\t MAE: 8.9337\t RMSE: 11.4994\n",
            " \n",
            "MAE: 8.2355\t RMSE: 10.4704\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.24.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.235468793798375\t rmse: 10.47040157093806\n",
            "****************************************************************\n",
            "Train Epoch: 39\t Learning rate: 0.0000\t Loss: 816.1676\t MAE: 9.1704\t RMSE: 11.5734\n",
            " \n",
            "MAE: 8.2414\t RMSE: 10.5102\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\t Loss: 868.6105\t MAE: 9.7597\t RMSE: 12.5221\n",
            " \n",
            "MAE: 8.2560\t RMSE: 10.5109\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\t Loss: 767.9132\t MAE: 8.6282\t RMSE: 10.9642\n",
            " \n",
            "MAE: 8.2608\t RMSE: 10.5003\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\t Loss: 729.4421\t MAE: 8.1960\t RMSE: 10.3365\n",
            " \n",
            "MAE: 8.2668\t RMSE: 10.4982\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\t Loss: 801.1752\t MAE: 9.0020\t RMSE: 11.4498\n",
            " \n",
            "MAE: 8.2586\t RMSE: 10.5061\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\t Loss: 777.8695\t MAE: 8.7401\t RMSE: 11.4400\n",
            " \n",
            "MAE: 8.2543\t RMSE: 10.5124\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\t Loss: 727.2822\t MAE: 8.1717\t RMSE: 10.5667\n",
            " \n",
            "MAE: 8.2510\t RMSE: 10.5189\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\t Loss: 764.4928\t MAE: 8.5898\t RMSE: 10.7617\n",
            " \n",
            "MAE: 8.2263\t RMSE: 10.4773\n",
            "\n",
            "=========================================================================================\n",
            "Saved as ../Model/Regression/Audio3/gru_vlad256_256_8.23.pt\n",
            "****************************************************************\n",
            "model saved: mae: 8.226305996930158\t rmse: 10.47725678011219\n",
            "****************************************************************\n",
            "Train Epoch: 47\t Learning rate: 0.0000\t Loss: 749.8636\t MAE: 8.4254\t RMSE: 10.6822\n",
            " \n",
            "MAE: 8.2370\t RMSE: 10.4453\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\t Loss: 740.6487\t MAE: 8.3219\t RMSE: 11.1334\n",
            " \n",
            "MAE: 8.2554\t RMSE: 10.4396\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\t Loss: 764.9958\t MAE: 8.5955\t RMSE: 10.9287\n",
            " \n",
            "MAE: 8.2506\t RMSE: 10.4418\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\t Loss: 754.1810\t MAE: 8.4739\t RMSE: 10.7480\n",
            " \n",
            "MAE: 8.2337\t RMSE: 10.4461\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\t Loss: 764.0817\t MAE: 8.5852\t RMSE: 10.5919\n",
            " \n",
            "MAE: 8.2341\t RMSE: 10.4599\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\t Loss: 716.7947\t MAE: 8.0539\t RMSE: 10.5199\n",
            " \n",
            "MAE: 8.2506\t RMSE: 10.5035\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\t Loss: 716.0958\t MAE: 8.0460\t RMSE: 10.1127\n",
            " \n",
            "MAE: 8.2805\t RMSE: 10.4919\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\t Loss: 666.8413\t MAE: 7.4926\t RMSE: 9.8947\n",
            " \n",
            "MAE: 8.2783\t RMSE: 10.5080\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\t Loss: 746.1957\t MAE: 8.3842\t RMSE: 10.9497\n",
            " \n",
            "MAE: 8.2921\t RMSE: 10.5628\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\t Loss: 748.4846\t MAE: 8.4099\t RMSE: 10.5865\n",
            " \n",
            "MAE: 8.3298\t RMSE: 10.6351\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\t Loss: 716.6420\t MAE: 8.0522\t RMSE: 9.9382\n",
            " \n",
            "MAE: 8.3618\t RMSE: 10.6806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\t Loss: 674.0636\t MAE: 7.5737\t RMSE: 9.6774\n",
            " \n",
            "MAE: 8.3754\t RMSE: 10.7210\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\t Loss: 724.4307\t MAE: 8.1397\t RMSE: 10.3369\n",
            " \n",
            "MAE: 8.3891\t RMSE: 10.7500\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\t Loss: 673.5614\t MAE: 7.5681\t RMSE: 9.5342\n",
            " \n",
            "MAE: 8.3649\t RMSE: 10.6923\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\t Loss: 705.5508\t MAE: 7.9275\t RMSE: 10.2842\n",
            " \n",
            "MAE: 8.3738\t RMSE: 10.6968\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\t Loss: 661.5691\t MAE: 7.4334\t RMSE: 9.5552\n",
            " \n",
            "MAE: 8.3655\t RMSE: 10.6624\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\t Loss: 704.1320\t MAE: 7.9116\t RMSE: 10.4158\n",
            " \n",
            "MAE: 8.3819\t RMSE: 10.6679\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\t Loss: 656.0256\t MAE: 7.3711\t RMSE: 9.5515\n",
            " \n",
            "MAE: 8.4310\t RMSE: 10.7823\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\t Loss: 682.4006\t MAE: 7.6674\t RMSE: 10.1075\n",
            " \n",
            "MAE: 8.4270\t RMSE: 10.7442\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\t Loss: 659.0770\t MAE: 7.4054\t RMSE: 9.6258\n",
            " \n",
            "MAE: 8.4280\t RMSE: 10.7325\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\t Loss: 654.6891\t MAE: 7.3561\t RMSE: 9.5205\n",
            " \n",
            "MAE: 8.4443\t RMSE: 10.7498\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\t Loss: 634.2596\t MAE: 7.1265\t RMSE: 9.1839\n",
            " \n",
            "MAE: 8.5055\t RMSE: 10.8391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\t Loss: 636.5305\t MAE: 7.1520\t RMSE: 9.3764\n",
            " \n",
            "MAE: 8.5157\t RMSE: 10.8504\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\t Loss: 679.2609\t MAE: 7.6321\t RMSE: 9.3391\n",
            " \n",
            "MAE: 8.5238\t RMSE: 10.8636\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\t Loss: 608.6858\t MAE: 6.8392\t RMSE: 8.8565\n",
            " \n",
            "MAE: 8.5331\t RMSE: 10.9003\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\t Loss: 627.4097\t MAE: 7.0495\t RMSE: 9.1899\n",
            " \n",
            "MAE: 8.5572\t RMSE: 10.9691\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\t Loss: 626.9426\t MAE: 7.0443\t RMSE: 9.2934\n",
            " \n",
            "MAE: 8.5575\t RMSE: 10.9212\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\t Loss: 523.7008\t MAE: 5.8843\t RMSE: 7.6359\n",
            " \n",
            "MAE: 8.5808\t RMSE: 10.9473\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\t Loss: 616.1357\t MAE: 6.9229\t RMSE: 9.0468\n",
            " \n",
            "MAE: 8.6058\t RMSE: 10.9887\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\t Loss: 562.3608\t MAE: 6.3187\t RMSE: 8.3413\n",
            " \n",
            "MAE: 8.6288\t RMSE: 11.0050\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\t Loss: 648.0372\t MAE: 7.2813\t RMSE: 9.1981\n",
            " \n",
            "MAE: 8.6260\t RMSE: 11.0118\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\t Loss: 614.7573\t MAE: 6.9074\t RMSE: 9.0351\n",
            " \n",
            "MAE: 8.6492\t RMSE: 11.0708\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\t Loss: 579.4680\t MAE: 6.5109\t RMSE: 8.0255\n",
            " \n",
            "MAE: 8.6656\t RMSE: 11.0985\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\t Loss: 603.9789\t MAE: 6.7863\t RMSE: 8.8736\n",
            " \n",
            "MAE: 8.6941\t RMSE: 11.1388\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\t Loss: 560.5719\t MAE: 6.2986\t RMSE: 8.6065\n",
            " \n",
            "MAE: 8.7187\t RMSE: 11.1673\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\t Loss: 561.9658\t MAE: 6.3142\t RMSE: 8.4383\n",
            " \n",
            "MAE: 8.7051\t RMSE: 11.1452\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\t Loss: 611.1263\t MAE: 6.8666\t RMSE: 9.0562\n",
            " \n",
            "MAE: 8.7449\t RMSE: 11.1743\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\t Loss: 541.1698\t MAE: 6.0806\t RMSE: 8.0698\n",
            " \n",
            "MAE: 8.7447\t RMSE: 11.1818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\t Loss: 549.5789\t MAE: 6.1750\t RMSE: 7.7857\n",
            " \n",
            "MAE: 8.7291\t RMSE: 11.1537\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\t Loss: 621.8787\t MAE: 6.9874\t RMSE: 8.9357\n",
            " \n",
            "MAE: 8.7432\t RMSE: 11.2231\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\t Loss: 556.3907\t MAE: 6.2516\t RMSE: 8.3163\n",
            " \n",
            "MAE: 8.7534\t RMSE: 11.2426\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\t Loss: 578.1514\t MAE: 6.4961\t RMSE: 8.6817\n",
            " \n",
            "MAE: 8.7369\t RMSE: 11.2156\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\t Loss: 583.4251\t MAE: 6.5553\t RMSE: 8.8737\n",
            " \n",
            "MAE: 8.7193\t RMSE: 11.1813\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\t Loss: 578.5530\t MAE: 6.5006\t RMSE: 8.8062\n",
            " \n",
            "MAE: 8.7205\t RMSE: 11.1810\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\t Loss: 568.9955\t MAE: 6.3932\t RMSE: 8.6583\n",
            " \n",
            "MAE: 8.7494\t RMSE: 11.2593\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\t Loss: 548.3611\t MAE: 6.1614\t RMSE: 7.8140\n",
            " \n",
            "MAE: 8.7413\t RMSE: 11.2289\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\t Loss: 584.7348\t MAE: 6.5701\t RMSE: 8.8430\n",
            " \n",
            "MAE: 8.7427\t RMSE: 11.2225\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\t Loss: 567.4627\t MAE: 6.3760\t RMSE: 8.0621\n",
            " \n",
            "MAE: 8.7729\t RMSE: 11.3020\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\t Loss: 582.3526\t MAE: 6.5433\t RMSE: 8.6764\n",
            " \n",
            "MAE: 8.7517\t RMSE: 11.2604\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\t Loss: 568.9374\t MAE: 6.3926\t RMSE: 8.7719\n",
            " \n",
            "MAE: 8.7593\t RMSE: 11.2790\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\t Loss: 541.3335\t MAE: 6.0824\t RMSE: 8.0800\n",
            " \n",
            "MAE: 8.7752\t RMSE: 11.3001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\t Loss: 534.2810\t MAE: 6.0032\t RMSE: 7.7986\n",
            " \n",
            "MAE: 8.7915\t RMSE: 11.3147\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\t Loss: 578.4298\t MAE: 6.4992\t RMSE: 8.2699\n",
            " \n",
            "MAE: 8.8099\t RMSE: 11.3544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\t Loss: 580.4897\t MAE: 6.5224\t RMSE: 8.2411\n",
            " \n",
            "MAE: 8.8352\t RMSE: 11.3989\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\t Loss: 544.6735\t MAE: 6.1199\t RMSE: 7.9198\n",
            " \n",
            "MAE: 8.8186\t RMSE: 11.3690\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\t Loss: 562.5255\t MAE: 6.3205\t RMSE: 8.1472\n",
            " \n",
            "MAE: 8.8276\t RMSE: 11.3697\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\t Loss: 501.7407\t MAE: 5.6375\t RMSE: 7.4937\n",
            " \n",
            "MAE: 8.8407\t RMSE: 11.3998\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\t Loss: 519.7879\t MAE: 5.8403\t RMSE: 7.8493\n",
            " \n",
            "MAE: 8.8530\t RMSE: 11.4433\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\t Loss: 534.6195\t MAE: 6.0070\t RMSE: 7.7423\n",
            " \n",
            "MAE: 8.8476\t RMSE: 11.4422\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\t Loss: 473.1680\t MAE: 5.3165\t RMSE: 7.1213\n",
            " \n",
            "MAE: 8.8583\t RMSE: 11.4787\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\t Loss: 604.9631\t MAE: 6.7973\t RMSE: 8.6321\n",
            " \n",
            "MAE: 8.8915\t RMSE: 11.5497\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\t Loss: 548.3815\t MAE: 6.1616\t RMSE: 7.9721\n",
            " \n",
            "MAE: 8.8863\t RMSE: 11.5308\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\t Loss: 535.7801\t MAE: 6.0200\t RMSE: 7.6060\n",
            " \n",
            "MAE: 8.8836\t RMSE: 11.5073\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\t Loss: 504.2339\t MAE: 5.6655\t RMSE: 7.3301\n",
            " \n",
            "MAE: 8.9478\t RMSE: 11.5803\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\t Loss: 540.8279\t MAE: 6.0767\t RMSE: 7.7133\n",
            " \n",
            "MAE: 8.9402\t RMSE: 11.5638\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\t Loss: 494.1913\t MAE: 5.5527\t RMSE: 7.1232\n",
            " \n",
            "MAE: 8.9659\t RMSE: 11.6140\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\t Loss: 588.1678\t MAE: 6.6086\t RMSE: 8.5360\n",
            " \n",
            "MAE: 8.9802\t RMSE: 11.6340\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\t Loss: 562.0663\t MAE: 6.3154\t RMSE: 8.0644\n",
            " \n",
            "MAE: 8.9563\t RMSE: 11.5873\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\t Loss: 550.4349\t MAE: 6.1847\t RMSE: 7.7636\n",
            " \n",
            "MAE: 8.9998\t RMSE: 11.6397\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\t Loss: 492.8281\t MAE: 5.5374\t RMSE: 7.0402\n",
            " \n",
            "MAE: 9.0455\t RMSE: 11.6866\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\t Loss: 494.4212\t MAE: 5.5553\t RMSE: 7.2327\n",
            " \n",
            "MAE: 9.0142\t RMSE: 11.6413\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\t Loss: 492.5363\t MAE: 5.5341\t RMSE: 7.0995\n",
            " \n",
            "MAE: 9.0521\t RMSE: 11.6974\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\t Loss: 511.0856\t MAE: 5.7425\t RMSE: 7.5177\n",
            " \n",
            "MAE: 9.0415\t RMSE: 11.7088\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\t Loss: 517.5915\t MAE: 5.8156\t RMSE: 7.5496\n",
            " \n",
            "MAE: 9.0812\t RMSE: 11.7659\n",
            "\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "for fold in range(3):\n",
        "    test_dep_idxs_tmp = dep_idxs[fold*10:(fold+1)*10]\n",
        "    test_non_idxs = non_idxs[fold*44:(fold+1)*44]\n",
        "    train_dep_idxs_tmp = list(set(dep_idxs) - set(test_dep_idxs_tmp))\n",
        "    train_non_idxs = list(set(non_idxs) - set(test_non_idxs))\n",
        "\n",
        "    # training data augmentation\n",
        "    train_dep_idxs = []\n",
        "    for (i, idx) in enumerate(train_dep_idxs_tmp):\n",
        "        feat = audio_features[idx]\n",
        "        if i < 14:\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                audio_targets = np.hstack((audio_targets, audio_targets[idx]))\n",
        "                train_dep_idxs.append(len(audio_features)-1)\n",
        "        else:\n",
        "            train_dep_idxs.append(idx)\n",
        "\n",
        "    # test data augmentation\n",
        "    # test_dep_idxs = []\n",
        "    # for idx in test_dep_idxs_tmp:\n",
        "    #     feat = audio_features[idx]\n",
        "    #     for i in itertools.permutations(feat, feat.shape[0]):\n",
        "    #         audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "    #         audio_targets = np.hstack((audio_targets, audio_targets[idx]))\n",
        "    #         test_dep_idxs.append(len(audio_features)-1)\n",
        "    test_dep_idxs = test_dep_idxs_tmp\n",
        "\n",
        "\n",
        "    model = AudioBiLSTM(config)\n",
        "\n",
        "    if config['cuda']:\n",
        "        model = model.cuda()\n",
        "\n",
        "    # optimizer = optim.Adam(model.parameters())\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    criterion = nn.L1Loss()\n",
        "    # criterion = FocalLoss(class_num=2)\n",
        "    min_mae = 100\n",
        "    min_rmse = 100\n",
        "    train_mae = 100\n",
        "\n",
        "\n",
        "    for ep in range(1, config['epochs']):\n",
        "        train_mae = train(ep)\n",
        "        tloss = evaluate(fold, model, train_mae)\n",
        "\n",
        "# ============== prep ==============\n",
        "# X_test = np.squeeze(np.load(os.path.join(prefix, 'Features/Audio/val_samples_reg_avid256.npz'))['arr_0'], axis=2)\n",
        "# Y_test = np.load(os.path.join(prefix, 'Features/Audio/val_labels_reg_avid256.npz'))['arr_0']\n",
        "# ============== prep ==============\n",
        "\n",
        "\n",
        "# ============== SVM ==============\n",
        "\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = audio_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = audio_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = SVR(kernel='linear', gamma='auto')\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "#     # break\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# ============== SVM ==============\n",
        "\n",
        "# # ============== DT ==============\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = audio_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = audio_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = DecisionTreeRegressor(max_depth=100, random_state=0, criterion=\"mse\")\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# # ============== DT ==============\n",
        "\n",
        "# # ============== RF ==============\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = audio_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = audio_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = RandomForestRegressor(max_depth=100, random_state=0, criterion=\"mse\")\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# # ============== RF ==============\n",
        "\n",
        "# ============== ada ==============\n",
        "# from sklearn.ensemble import AdaBoostRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# X = audio_features[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# Y = audio_targets[train_dep_idxs+train_non_idxs+test_dep_idxs+test_non_idxs]\n",
        "# kf = KFold(n_splits=3)\n",
        "# regr = AdaBoostRegressor(n_estimators=50)\n",
        "# maes, rmses = [], []\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#     # X_train, X_test = X[train_index], X[test_index]\n",
        "#     # Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "#     X_train, Y_train = X[train_index], Y[train_index]\n",
        "#     regr.fit([f.flatten() for f in X_train], Y_train)\n",
        "#     pred = regr.predict([f.flatten() for f in X_test])\n",
        "\n",
        "#     mae = mean_absolute_error(Y_test, pred)\n",
        "#     rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
        "#     maes.append(mae)\n",
        "#     rmses.append(rmse)\n",
        "\n",
        "#     print('MAE: {:.4f}\\t RMSE: {:.4f}\\n'.format(mae, rmse))\n",
        "#     print('='*89)\n",
        "\n",
        "# print(np.mean(maes), np.mean(rmses))\n",
        "# ============== ada ==============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjUj6Jzm4-7Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
